<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>A Fast Address Sanity Checker（谷歌AddressSanity论文翻译）</title>
      <link href="/2020/01/18/AddressSanityChecker/"/>
      <url>/2020/01/18/AddressSanityChecker/</url>
      
        <content type="html"><![CDATA[<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>对于C和C ++等编程语言，包括缓冲区溢出和堆内存的释放后重用等内存访问错误仍然是一个严重的问题。存在许多内存错误检测器，但大多数检测器要么运行缓慢，要么检测到的错误类型有限，或者两者兼而有之。<br>&emsp;&emsp;本文介绍了一种新的内存错误检测器AddressSanitizer。我们的工具能够发现堆、堆栈和全局对象的越界访问，以及释放后重用的错误。它采用了专门的内存分配器和代码插桩，该插桩足够简单，可以在任何编译器，二进制翻译系统甚至硬件中实现。<br>&emsp;&emsp;AddressSanitizer在不牺牲全面性的情况下实现了效率。它对程序运行速度的平均仅为下降73％，但它可以在错误发生时准确地捕捉到。它在Chromium浏览器中发现了300多个未知的错误，在其他软件中也发现了许多错误。  </p><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h2><p>&emsp;&emsp;市场上有数十种内存错误检测工具[3、8、11、13、15、21、23、24]。 这些工具在速度，内存消耗，可检测到的错误类型，检测到错误的概率，支持的平台以及其他特性方面有所不同。 许多工具可以成功地检测到各种各样的错误，但是会产生高昂的开销，或者开销低但检测到bug更少。 我们介绍了AddressSanitizer，这是一种将性能和覆盖范围相结合的新工具。 AddressSanitizer可以发现越界访问（用于堆，堆栈和全局对象）和释放的堆内存的使用，相对较低的73％的速度下降，并且内存使用量增加了3.4倍，使其成为C / C ++应用程序测试领域中的理想选择 。<br>&emsp;&emsp;AddressSanitizer由两部分组成：一个插桩模块和一个运行时库。 <strong>插桩模块修改代码，以在每次内存访问时检查影子状态，并在堆栈和全局对象周围创建poisoned redzones，以检测上溢和下溢。 当前的实现基于LLVM [4]编译器基础结构。 运行时库替换malloc，free和相关函数，在分配的堆区周围创建poisoned redzones，延迟释放堆区的访问并进行错误报告。</strong>  </p><h3 id="1-1-贡献"><a href="#1-1-贡献" class="headerlink" title="1.1 贡献"></a>1.1 贡献</h3><p>在本文中，我们：  </p><ul><li>表明内存错误检测器可以利用影子内存获得比传统方法低得多的开销和全面性；  </li><li>提出了一种新颖的影子状态编码，可实现紧凑的影子内存（多达128对1的映射），用于检测越界和释放后重用的bug   </li><li>描述针对我们的影子编码的专用内存分配器；   </li><li>评估一个新的可以有效识别内存错误的公开可用的工具。  </li></ul><h3 id="1-2-大纲"><a href="#1-2-大纲" class="headerlink" title="1.2 大纲"></a>1.2 大纲</h3><p>&emsp;&emsp;在下一节总结了相关工作之后，我们将在第3节中介绍AddressSanitizer算法。第4节提供了使用AddressSanitizer的实验结果。我们在第5节中讨论了进一步的改进，然后总结了本文。  </p><h2 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2 相关工作"></a>2 相关工作</h2><p>本节探讨了现有的内存检测工具和技术。  </p><h3 id="2-1-影子内存"><a href="#2-1-影子内存" class="headerlink" title="2.1 影子内存"></a>2.1 影子内存</h3><p>许多不同的工具使用影子内存来存储与每个应用程序数据相对应的元数据。通常，应用程序地址通过直接缩放和偏移量映射到影子地址，其中整个应用程序地址空间映射到单个影子地址空间，或者通过表查找进行级别转换。直接映射的示例包括TaintTrace [10]和LIFT [26]。 TaintTrace需要一个与应用程序地址空间大小相等的影子空间，这将导致使用超过一般地址空间的正常应用程序无法适应，LIFT中的影子空间是应用程序空间的八分之一。<br>&emsp;&emsp;为了在地址空间布局中提供更大的灵活性，某些工具使用了多级转换方案。 Valgrind [20]和Dr. Memory [8]将它们的影子内存分成几部分，并使用表查找来获取影子地址，这需要额外的内存负载。对于64位平台，Valgrind对32GB地址空间以外的应用程序地址使用附加的表转换。<br>&emsp;&emsp;Umbra [30，31]结合了布局灵活性和效率，避免了通过非均匀且动态调整的缩放比例和偏移方案进行表格查找。Bound- Less [9]将其某些元数据存储在64位指针的16个较高位中，但在慢速路径上会回落到更传统的影子内存中。 LBC [12]使用存储在应用程序内存中的特殊值执行快速路径检查，并依赖慢速路径上的两级影子存储器。  </p><h3 id="2-2-插桩"><a href="#2-2-插桩" class="headerlink" title="2.2 插桩"></a>2.2 插桩</h3><p>&emsp;&emsp;大量的内存错误检测器基于二进制插桩。 其中最受欢迎的是Valgrind（Memcheck）[21]，Dr.Memory [8]，Purify [13]，BoundsChecker [17]，Intel Parallel Inspector [15]和Discover [23]。 这些工具可以发现堆内存的越界和释放后重用错误，并且（通常）没有误报。 据我们所知，没有一种基于二进制插桩的工具可以在堆栈（除了堆栈顶部以外）或全局变量中发现越界错误。不过这些工具还可以查找未初始化访问错误（注：这是AddressSanitizer未支持的）。<br>&emsp;&emsp;Mudflap [11]使用编译时工具，因此能够检测堆栈对象的越界访问。 但是，它不会在一个堆栈帧中的不同堆栈对象之间插Redzone，因此不会检测到所有堆栈缓冲区溢出错误。 它在复杂的C ++代码中有较高的漏报率(false positive)。<br>&emsp;&emsp;CCured [19]将检测与静态分析结合在一起（仅适用于C程序），以消除冗余的检查。 它们的插桩与非插桩库不兼容。<br>&emsp;&emsp;LBC [12]使用源到源转换，并依靠CCured消除冗余检查。 LBC仅限于C语言，并且不检测释放后重用错误。<br>&emsp;&emsp;Insure ++ [24]主要依靠编译时插桩，但也可以使用二进制插桩。它的实施细节尚未公开。 </p><h3 id="2-3-调试分配器"><a href="#2-3-调试分配器" class="headerlink" title="2.3 调试分配器"></a>2.3 调试分配器</h3><p>另一类内存错误检测器使用专用的内存分配器，不会更改其它部分的代码执行。<br>&emsp;&emsp;Electric Fenc[25]，Duma [3]，GuardMalloc [16]和Page Heap [18]等工具都使用CPU页保护。每个分配的区域都放入一个专用页面（或一组页面）中。被特殊分配的页（右边或/和左边）标记为不可访问。随后将访问这些页面的页面错误报告为越界错误。这些工具会占用大量内存，并且在malloc密集型应用程序上可能会非常慢（因为每个malloc至少需要一个系统调用）。而且，这些工具可能会遗漏某些类型的错误（例如，从5字节内存区域的开头读取偏移量为6的字节）。如果报告了错误，则会在错误消息中提供相应的说明。<br>&emsp;&emsp;其他一些malloc实现，包括DieHarder [22]（DieHard [5] malloc的后代）和Dmalloc [2]，都是在概率和/或延迟的基础上发现内存错误的。他们修改后的malloc函数在返回给用户的内存区域周围添加了redzones，并使用特殊的魔术字节填充新分配的内存，free函数也会将魔术字节写入free后的内存区。<br>&emsp;&emsp;如果程序读取了魔术字节，则判定程序进行了越界读取或或读取了未初始化的值。但是，它无法立即发现这种错误。通过正确选择魔术字节，程序可能会以可检测错误的方式地运行（DieHard [5]具有复制模式，通过比较模式，它可以检测到这种错误行为。初始化为不同魔术字节的几个程序副本的输出）。换句话说，对越界读取和释放后重用的检测是概率性的。<br>&emsp;&emsp;<strong>如果Redzone中的魔术字节被覆盖了，则后面的free函数中会检测这一情况，但该工具无法确切知道何时发生越界写入或释放后写入</strong>。 对于大型程序，它通常等效于报告“您的程序有bug”。 请注意，DieHarder的目标不仅是检测错误，而且还可以防止受到安全攻击。<br>&emsp;&emsp;两种malloc调试方法通常结合在一起。但调试malloc工具不处理堆栈或全局变量。<br>&emsp;&emsp;相同的魔术字节技术通常用于缓冲区溢出保护。 StackGuard [29]和ProPolice [14]（GCC当前使用的StackGuard重新实现）在当前堆栈帧的局部变量和返回地址之间放置一个canary值，并在函数退出时检查该值的一致性。 这有助于防止堆栈破坏缓冲区溢出，但无法检测到对堆栈对象的任意越界访问。   </p><h2 id="3-地址消毒算法"><a href="#3-地址消毒算法" class="headerlink" title="3 地址消毒算法"></a>3 地址消毒算法</h2><p>从顶层角度来看，我们的内存错误检测方法与基于Valgrind的工具AddrCheck [27]相似：使用影子内存记录应用程序内存的每个字节是否可以安全访问，并在应用程序每次加载和存储内存时，使用插桩检查影子内存。 但是，<strong>AddressSanitizer使用更高效的影子内存映射，更紧凑的影子内存映射编码，除了堆内存错误之外还可以检测堆栈和全局变量中的错误，并且比AddrCheck快一个数量级</strong>。 以下各节介绍了AddressSanitizer如何编码和映射其影子内存，指令插入以及其运行时库如何运行。  </p><h3 id="3-1-影子内存"><a href="#3-1-影子内存" class="headerlink" title="3.1 影子内存"></a>3.1 影子内存</h3><p>malloc函数返回的内存地址通常至少8个字节对齐。这让我们观察到应用程序堆内存的任何对齐的8字节序列处于9种不同状态之一：前k（0≤k≤8）个字节是可寻址的，而其余的8 − k个字节则不可寻址。可以使用单个字节的影子内存编码该状态。<br>&emsp;&emsp;AddressSanitizer将虚拟地址空间的八分之一专用于其影子内存，并使用具有比例和偏移量的应用程序地址转换为其对应的影子地址。给定应用程序内存地址Addr，影子字节的地址计算为<code>(Addr &gt;&gt; 3)+ Offset</code>。如果Max-1是虚拟地址空间中的最大有效地址，则应选择Offset的值，以使启动时不占用从Offset到Offset + Max / 8的区域。与Umbra [31]不同，每个平台都必须静态选择Offset，但是我们并不认为这是一个严重的限制。在虚拟地址空间为0x00000000-0xffffffff的典型32位Linux或MacOS系统上，我们使用Offset = 0x20000000（2^29）。在具有47个有效地址位的64位系统上，我们使用Offset = 0x0000100000000000（2^44）。在某些情况下（例如，在Linux上带有-fPIE / -pie编译器标志），零偏移量可用于进一步简化检测过程。<br><img src="A%20Fast%20Address%20Sanity%20Checker-2020-01-16-17-47-45.png" alt=""><br>&emsp;&emsp;图1显示了地址空间布局。应用程序内存分为两部分（低和高），它们分别映射到相应的影子区域(8字节对齐的映射)。将影子内存区域地址映射到Bad区域中，通过页面保护标记为无法访问的（保证影子内存区域不会被程序正常部分访问）。<br>&emsp;&emsp;我们为每个影子字节使用以下编码：0表示对应的应用程序内存区的所有8个字节都是可寻址的； k（1≤k≤7）表示前k个字节是可寻址的；任何负值表示整个8字节字都是不可寻址的。我们使用不同的负值来区分不同类型的不可寻址内存（堆redzones，堆栈redzones，全局redzones，已释放redzones）。<br>&emsp;&emsp;该影子映射可以推广为（Addr &gt;&gt; Scale）+ Offset形式，其中Scale是1 … 7之一。在Scale = N的情况下，影子内存占用虚拟地址空间的1/2^N，并且redzones（和malloc对齐）的最小大小为2^N字节。每个影子字节描述2^N个字节的状态，并编码2^N +1个不同的值。较大的Scale值需要较少的影子内存，但需要较大的redzones才能满足对齐要求。大于3的Scale值要求对8字节访问进行更复杂的配置（请参阅第3.2节），但对于可能无法放弃其地址空间的单个连续八分之一的应用程序，则提供了更大的灵活性。  </p><h3 id="3-2-插桩"><a href="#3-2-插桩" class="headerlink" title="3.2 插桩"></a>3.2 插桩</h3><p>挡检测8字节内存访问时，Address- Sanitizer计算相应影子字节的地址，加载该字节，然后检查其是否为零：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ShadowAddr &#x3D; (Addr &gt;&gt; 3) + Offset;  </span><br><span class="line">if (*ShadowAddr !&#x3D; 0)  </span><br><span class="line">    ReportAndCrash(Addr);</span><br></pre></td></tr></table></figure><br>当检测1、2或4字节访问时，检测稍微复杂一些：如果影子值是正数（即，只有8字节字中的前k个字节是可寻址的），我们需要比较访问地址的后3位与访问大小是否超出k值。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ShadowAddr &#x3D; (Addr &gt;&gt; 3) + Offset;</span><br><span class="line">k &#x3D; *ShadowAddr;</span><br><span class="line">if (k !&#x3D; 0 &amp;&amp; ((Addr &amp; 7) + AccessSize &gt; k))</span><br><span class="line">   ReportAndCrash(Addr);</span><br></pre></td></tr></table></figure><br>在这两种情况下，对于原始代码中的每个内存访问，检测仅插入一个内存读取。我们假定N字节访问与N对齐。如第3.5节中所述，Address- Sanitizer可能会丢失由未对齐访问引起的错误。<br>&emsp;&emsp;我们将AddressSanitizer的代码插桩过程放到LLVM优化流水线中非常靠后的位置，这样我们就只会对那些经过LLVM优化器优化后残余的内存访问进行插桩，减少了不必要的插入。例如，将不会检测对通过LLVM优化的本地堆栈对象的内存访问。同时，我们不必检测由LLVM代码生成器生成的内存访问（例如，寄存器溢出）。<br>&emsp;&emsp;错误报告代码（ReportAndCrash（Addr））最多执行一次，但是已插入到代码中的许多位置，因此仍然需要保持紧凑。当前，我们使用一个简单的函数调用（请参阅附录A中的示例）。另一个选择是使用生成硬件异常的指令。  </p><h3 id="3-3-运行时库"><a href="#3-3-运行时库" class="headerlink" title="3.3 运行时库"></a>3.3 运行时库</h3><p>运行时库的主要目的是管理影子内存。<strong>在应用程序启动时，将映射整个影子区域，以便该程序的其他任何部分都不能使用它</strong>。 影子内存得到保护。 在Linux上，影子内存空间在启动时始终不被占用，因此内存映射总是成功的。 在MacOS上，我们需要禁用地址空间布局随机化（ASLR）。 我们的初步实验表明，相同的影子内存布局也适用于Windows。<br>&emsp;&emsp;malloc和free函数被特殊插桩替换。 malloc函数在返回的区域周围分配额外的内存，即redzone。redzone被标记为不可寻址或poisoned。redzone越大，检测到的上溢或下溢越大。<br>&emsp;&emsp;在分配器内部，内存区域被组织为与一系列大小相对一样的free chunk数组。当与请求的chunk大小相对应的空闲列表为空时，会从操作系统中分配一大组带有redzone的内存区域（例如，使用mmap）。对于n个区域，我们分配n +1个redzone，这样一个区域的右redzone通常是另一区域的左redzone：<br><code>rz1 mem1 rz2 mem2 rz3 mem3 rz4</code><br>&emsp;&emsp;左边redzone会用于存储分配器的内部数据（例如分配大小，线程ID等）；因此，堆redzone的最小大小当前为32个字节。缓冲区下溢不会破坏此内部数据，因为此类下溢会在实际溢出之前立即检测到（如果下溢发生在检测代码中）。<br>&emsp;&emsp;free函数会对整个free内存poisoned，并将其放入隔离区，这样malloc不会很快就分配该区域。当前，隔离区被实现为FIFO队列，该队列可随时保存固定数量的内存。<br>&emsp;&emsp;默认情况下，malloc和free记录当前的调用堆栈，以提供更多有用的错误报告。 malloc调用堆栈存储在左侧的redzone中（红redzone越大，可以存储的帧数越多），而free调用堆栈存储在内存区域本身的开头。<br>4.3节讨论了如何调整运行时库。  </p><h3 id="3-4-栈和全局变量"><a href="#3-4-栈和全局变量" class="headerlink" title="3.4 栈和全局变量"></a>3.4 栈和全局变量</h3><p>为了检测对全局对象和堆栈对象的越界访问，AddressSanitizer必须在此类对象周围创建中毒的红色区域。 对于全局变量，将在编译时创建redzone，并将redzone的地址在应用程序启动时传递给运行时库。 运行时库函数使redzone poisoned（标记不可安全访问），并记录地址以进一步报告错误。 对于堆栈对象，将在运行时创建redzone并使其poisoned。 当前，使用32字节的redzone（加上最多31字节用于对齐）。 例如，给定一个程序<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">void foo() &#123;  </span><br><span class="line">    char a[10];  </span><br><span class="line">    &lt;function body&gt; &#125;</span><br></pre></td></tr></table></figure><br>转为为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">void foo() &#123;</span><br><span class="line">    char rz1[32]</span><br><span class="line">    char arr[10];</span><br><span class="line">    char rz2[32-10+32];</span><br><span class="line">    unsigned *shadow &#x3D;</span><br><span class="line">    (unsigned*)(((long)rz1&gt;&gt;8)+Offset);</span><br><span class="line">    &#x2F;&#x2F; poison the redzones around arr.</span><br><span class="line">    shadow[0] &#x3D; 0xffffffff; &#x2F;&#x2F; rz1</span><br><span class="line">    shadow[1] &#x3D; 0xffff0200; &#x2F;&#x2F; arr and rz2</span><br><span class="line">    shadow[2] &#x3D; 0xffffffff; &#x2F;&#x2F; rz2</span><br><span class="line">    &lt;function body&gt;</span><br><span class="line">    &#x2F;&#x2F; un-poison all.</span><br><span class="line">    shadow[0] &#x3D; shadow[1] &#x3D; shadow[2] &#x3D; 0; &#125;</span><br></pre></td></tr></table></figure></p><h3 id="3-5-假阴性"><a href="#3-5-假阴性" class="headerlink" title="3.5 假阴性"></a>3.5 假阴性</h3><p>上面描述的检测方案可能会漏掉非常罕见的错误类型：部分超出范围的未对齐访问。 例如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int *a &#x3D; new int[2]; &#x2F;&#x2F; 8-aligned  </span><br><span class="line">int *u &#x3D; (int*)((char*)a + 6);  </span><br><span class="line">*u &#x3D; 1; &#x2F;&#x2F; Access to range [6-9]</span><br></pre></td></tr></table></figure><br>目前，我们忽略了这种类型的错误，因为我们提出的所有解决方案都会拖慢通用的检测路径。我们考虑的解决方案包括：  </p><ul><li>在运行时检查地址是否未对齐；  </li><li>使用字节到字节的阴影映射（仅在64位系统上可行）；  </li><li>使用更紧凑的映射（例如，第3.1节中的Scale = 7）以最小化遗漏此类错误的可能性。<br>在以下两种情况下，AddressSanitizer可能还会遗漏错误（Valgrind或Dr. Memory等工具存在相同的问题）。 首先，如果越界访问的内存距离分配的redzone太远，它可能会落在其它的有效分配中，AddressSanitizer会漏掉该错误。  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">char *a &#x3D; new char[100];</span><br><span class="line">char *b &#x3D; new char[1000];</span><br><span class="line">a[500] &#x3D; 0; &#x2F;&#x2F; may end up somewhere in b</span><br></pre></td></tr></table></figure>所有越界访问落到堆redzone中，会100％的概率检测到。如果内存占用不是一个严格的限制，我们建议使用最大为128个字节的大红色区域。 其次，如果在“空闲”和后续使用之间分配并释放了大量内存，则释放后重用错误可能无法被检测到。  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">char *a &#x3D; new char[1 &lt;&lt; 20]; &#x2F;&#x2F; 1MB</span><br><span class="line">delete [] a; &#x2F;&#x2F; &lt;&lt;&lt; &quot;free&quot;</span><br><span class="line">char *b &#x3D; new char[1 &lt;&lt; 28]; &#x2F;&#x2F; 256MB</span><br><span class="line">delete [] b; &#x2F;&#x2F; drains the quarantine queue.</span><br><span class="line">char *c &#x3D; new char[1 &lt;&lt; 20]; &#x2F;&#x2F; 1MB</span><br><span class="line">a[0] &#x3D; 0; &#x2F;&#x2F; &quot;use&quot;. May land in ’c’.</span><br></pre></td></tr></table></figure></li></ul><h3 id="3-6-假阳性"><a href="#3-6-假阳性" class="headerlink" title="3.6 假阳性"></a>3.6 假阳性</h3><p><strong>简单的来说，AddressSanitizer没有误报</strong>。 但是，在AddressSanitizer的开发和部署过程中，我们看到了下面描述的许多非期望的错误报告，现在已修复了所有错误报告。  </p><h4 id="3-6-1-与Widening编译选项的冲突"><a href="#3-6-1-与Widening编译选项的冲突" class="headerlink" title="3.6.1 与Widening编译选项的冲突"></a>3.6.1 与Widening编译选项的冲突</h4><p>一个非常常见的编译器优化（称为负载扩展）与AddressSanitizer插桩冲突。 考虑以下C代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">struct X &#123; char a, b, c; &#125;;</span><br><span class="line">    void foo() &#123;</span><br><span class="line">    X x; ...</span><br><span class="line">    ... &#x3D; x.a + x.c; &#125;</span><br></pre></td></tr></table></figure><br>在此代码中，对象x的大小为3，对齐方式为4（至少）。 负载加宽将x.a + x.c转换为一个4字节的负载，该负载部分跨越了对象边界。按照之前的栈代码插入方式，第4个字节应该是被染毒的，这样在load这4个字节时，就会报错。为避免此问题，当启用AddressSanitizer工具时，我们部分禁用了LLVM中的负载扩展。 我们仍然允许将x.a + x.b扩展为2字节的负载，因为这样的转换不会导致误报，并且会加快检测代码的速度。   </p><h4 id="3-6-2-与clone系统调用的冲突"><a href="#3-6-2-与clone系统调用的冲突" class="headerlink" title="3.6.2 与clone系统调用的冲突"></a>3.6.2 与clone系统调用的冲突</h4><p>在clone系统调用的存在下，我们已经观察到一些错误的报告。 首先，一个进程使用CLONE VM | CLONE FILES标志clone，这将创建一个与父进程共享内存的子进程。 特别是，子进程的堆栈使用的内存仍然属于父级。 然后，子进程调用一个函数，该函数在堆栈上具有对象，并且AddressSanitizer插桩poisoning堆栈对象的redzone。 最后，子进程不会退出函数且不会使redzone poisoning，而是调用永不返回的函数（例如exit或exec）。 结果，部分父地址空间仍然poisoning，并且在重新使用此内存后，AddressSanitizer会报告错误。 我们通过找到永不返回函数调用（退出或exec之类的函数具有此属性）并在调用之前un-poisoning整个堆栈内存来解决此问题。 由于类似的原因，AddressSanitizer运行时库必须拦截longjmp和C ++异常。  </p><h4 id="3-6-3-野生引用"><a href="#3-6-3-野生引用" class="headerlink" title="3.6.3 野生引用"></a>3.6.3 野生引用</h4><p>我们已经看到了几种情况，其中函数有意读取野生内存位置。 例如，低级代码在跨越多个堆栈帧的堆栈上的两个地址之间进行迭代。 对于这些情况，我们实现了没有地址安全性分析的函数属性，应将其添加到C / C ++源代码中的函数声明中。 这些情况很少见； 例如，在Chromium浏览器中，我们只需要一次此属性。   </p><h4 id="3-6-4-线程"><a href="#3-6-4-线程" class="headerlink" title="3.6.4 线程"></a>3.6.4 线程</h4><p>AddressSanitizer是线程安全的。 仅当无法访问相应的应用程序内存时（在malloc或free内部，在创建或销毁堆栈帧期间，在模块初始化期间），才修改影子内存。读取影子内存的所有其他访问，malloc和free函数使用线程本地缓存来避免每次调用都被锁定（就像大多数现代malloc实现一样）。 如果原始程序在内存访问和删除该内存之间存在竞争，则AddressSanitizer有时可能会将其检测为释放后使用的bug，但不能保证。 记录每个malloc和free的线程ID，并在错误消息中与线程创建调用堆栈一起报告线程ID。   </p><h2 id="4-评估"><a href="#4-评估" class="headerlink" title="4 评估"></a>4 评估</h2><p>我们根据SPEC CPU2006 [28]的C/C ++基准，测试了AddressSanitizer的性能。测试是在2个四核Intel Xeon E5620 CPU和24GB RAM的HP Z600机器上以64位模式完成的。 我们将插桩二进制文件的性能与使用常规LLVM编译器（clang -O2）构建的二进制文件进行比较。我们使用了32字节的Redzone，在malloc和free期间禁用了堆栈unwinding，并将隔离区大小设置为零（请参见第4.3节）。<br><img src="A%20Fast%20Address%20Sanity%20Checker-2020-01-17-15-53-26.png" alt=""><br>&emsp;&emsp;图2显示，CPU2006的平均速度降低了73％。 在perlbench和xalancbmk上看到的降幅最大（分别为2.60x和2.67x）。 这两个基准测试非常耗费内存，并且进行大量的1字节和2字节内存访问（两个基准测试都是文本处理程序）。 当仅检测写入时，我们还测量了AddressSanitizer的性能：平均速度下降了26％。 此模式可用于对性能有严格要求的环境中，以查找内存错误的子集。<br>&emsp;&emsp;在CPU2006环境中发现了三个错误：h264ref中的一个堆栈和一个全局缓冲区溢出，以及perlbench中的use-after realloc。<br>&emsp;&emsp;我们还评估了不同映射Scale和Offset值的性能（请参阅第3.1节）。大于3的Scale值代码执行速度平均会稍慢（与Scale = 3相比，从2％加速到15％减速）。 Scale = 4,5的内存占用量接近Scale = 3的内存占用量。对于值6和7，由于需要更大的redzone，因此内存占用量更大。将“偏移量”设置为零（需要-fPIE / -pie）可实现较小的加速，将CPU2006的平均速度降低到69％。<br><img src="A%20Fast%20Address%20Sanity%20Checker-2020-01-17-15-53-47.png" alt=""><br>&emsp;&emsp;表1总结了内存使用量的增加（通过在进程终止时从/ proc / self / status中读取VmPeak字段来收集）。内存开销主要来自malloc Redzone。平均内存使用量增加了3.37倍。隔离区还有一个固定大小的开销，我们没有在实验中计算。<br><img src="A%20Fast%20Address%20Sanity%20Checker-2020-01-17-15-47-52.png" alt=""><br>&emsp;&emsp;表2总结了堆栈大小的增加（/ proc / self / status中的VmStk字段）。只有6个基准测试的堆栈大小发生了明显变化，只有3个基准测试的堆栈大小增加了10％以上。 SPEC CPU2006的二进制大小增加范围是1.5倍至3.2倍，平均为2.5倍。  </p><h3 id="4-1-比较"><a href="#4-1-比较" class="headerlink" title="4.1 比较"></a>4.1 比较</h3><p>将AddressSanitizer与其他工具进行比较比较棘手，因为其他工具会发现不同的错误集。 Valgrind和Dr.Memory在CPU2006上分别导致速度降低20倍和10倍[8]。但是这些工具会检测到一组不同的错误（除了越界和释放后使用，它们还会检测未初始化的读取和内存泄漏，但不会处理大多数堆栈变量和全局变量的越界）。<br>&emsp;&emsp;Mudflap可能是与Address Sanitizer最相似的工具，具有非常不寻常的性能特征。根据我们的测量，Mudflap在CPU2006上的速度降低了2倍至41倍；多个基准测试因内存不足错误而失败。<br>&emsp;&emsp;使用CPU保护页的Debug malloc通常只会使占用malloc的较多的应用程序的速度。 Duma是Linux的免费保护页实现，在18个CPU2006基准测试中有12个崩溃，并出现内存不足错误。毫不奇怪：Duma手册将其描述为“terrible memory hog”。在其余6个基准上，它的开销很小（从-1％到5％）。 DieHarder Debug malloc的开销非常低，平均为20％[22]。但是，在三个内存分配密集型基准上，它可以与AddressSanitizer的开销进行比较：perlbench，2x； omn​​etpp，1.85倍； xalancbmk，1.75倍。  </p><h3 id="4-2-AddressSanitizer部署"><a href="#4-2-AddressSanitizer部署" class="headerlink" title="4.2 AddressSanitizer部署"></a>4.2 AddressSanitizer部署</h3><p>自2011年5月发布以来，Chromium开源浏览器[1]已通过AddressSanitizer进行了定期测试。在测试的前10个月中，该工具在Chromium代码和第三方库中检测到300多个未知的错误。 210个错误是堆释放后重用的错误，73个错误是堆缓冲区溢出，8个全局缓冲区溢出，7个堆栈缓冲区溢出和1个memcpy参数重叠。在另外13种情况下，Address- Sanitizer触发了其他类型的程序错误（例如，未初始化的内存读取），但未提供有意义的错误信息。<br>&emsp;&emsp;Chromium中错误报告的两个主要来源是现有单元测试的定期运行和目标随机测试生成（模糊测试）。无论哪种情况，检测代码的速度都是至关重要的。对于单元测试，高速允许使用更少的机器来跟上源代码的变化。对于模糊测试，它允许在短短的几秒钟内运行随机测试（由于AddressSanitizer被实现为编译时工具，因此没有启动代价），一旦发现错误，请在合理的时间内最小化测试。通过手动运行检测的浏览器发现了少数错误，而使用非常慢的工具则无法发现错误。<br>&emsp;&emsp;除了Chromium，我们还测试了大量其他代码，并发现了许多错误。就像在Chromium中一样，堆释放后重用是最常见的错误。但是，堆栈和全局缓冲区溢出的发生率比Chromium中的高。在LLVM本身中检测到了多个堆释放后重用。我们收到有关AddressSanitizer在Firefox，Perl，Vim和其他几个开源项目中发现的错误的通知。  </p><h3 id="4-3-调整精度和资源使用"><a href="#4-3-调整精度和资源使用" class="headerlink" title="4.3  调整精度和资源使用"></a>4.3  调整精度和资源使用</h3><p>AddressSanitizer具有三个主要徐昂行，这些选项会影响准确性和资源使用情况。  </p><ul><li>堆栈展开深度（默认值：30）<br>在每次调用malloc和free时，该工具都需要释放调用堆栈，以便错误消息包含更多信息。此选项影响工具的速度，尤其是在测试的应用程序是malloc密集型的情况下。它不会影响内存空间或错误发现能力，但较浅的堆栈跟踪通常不足以分析错误消息。  </li><li>隔离区大小（默认值：256MB）<br>该值控制查找释放后使用堆的错误的能力（请参见第3.5节）。它不影响性能。  </li><li>堆redzone的大小（默认值：128个字节<br>此选项影响查找堆缓冲区溢出错误的能力（请参见第3.5节）。较大的值可能会导致显着的减慢并增加内存使用量，尤其是在经过测试的程序分配许多小的堆内存块的情况下。由于redzone用于存储malloc调用堆栈，因此减小redzone会自动减小最大展开深度。   </li></ul><p>&emsp;&emsp;在测试Chromium时，我们使用了这三个参数的默认值。增加它们中的任何一个都不会增加发现错误的能力。在测试其他软件时，有时我们必须使用较小的redzone大小（32或64字节）和/或完全禁用堆栈展开，以满足极端的内存和速度限制。在具有少量RAM的环境中，我们使用了较小的隔离区大小。这三个值均由环境变量控制，可以在流程启动时设置。  </p><h2 id="5-未来工作"><a href="#5-未来工作" class="headerlink" title="5 未来工作"></a>5 未来工作</h2><p>本节讨论可以使用AddressSanitizer进行的改进和进一步的计划。   </p><h3 id="5-1-实时编译的优化"><a href="#5-1-实时编译的优化" class="headerlink" title="5.1 实时编译的优化"></a>5.1 实时编译的优化</h3><p>不必对所有内存插桩就可以发现所有内存错误。 可以消除冗余的插桩，如以下示例所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">void inc(int *a) &#123;</span><br><span class="line">    (*a)++; &#125;</span><br></pre></td></tr></table></figure><br>在这里，我们有两个内存访问，一个加载和一个存储，但是我们只需要检测第一个。 这是AddressSanitizer当前实现的唯一编译时优化。 下面介绍了一些其他可能的优化。 这些优化仅在某些条件下适用（例如，在第一个示例中，两次访问之间不应有非纯函数调用）。  </p><ul><li>仅对第一个访问进行检测： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">*a &#x3D; ...</span><br><span class="line">if (...)</span><br><span class="line">    *a &#x3D; ...</span><br></pre></td></tr></table></figure></li><li>仅对第二次访问进行检测（尽管这放弃了保证在实际加载或存储之前报告错误的属性）：  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if (...)</span><br><span class="line">    *a &#x3D; ...</span><br><span class="line">    *a &#x3D; ...</span><br></pre></td></tr></table></figure></li><li>仅对a[0]和a[n-1]插桩  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for (int i &#x3D; 0; i &lt; n; i++)</span><br><span class="line">    a[i] &#x3D; ...;</span><br></pre></td></tr></table></figure>我们已经使用这种方法来检测诸如memset，memcpy之类的函数。 如果n大，可能会遗漏一些错误。   </li><li>合并两种访问  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">struct &#123; int a, b; &#125; x; ...</span><br><span class="line">x.a &#x3D; ...;</span><br><span class="line">x.b &#x3D; ...;</span><br></pre></td></tr></table></figure></li><li>不对静态就能检测的进行插桩：  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int x[100];</span><br><span class="line">for (int i &#x3D; 0; i &lt; 100; i++)</span><br><span class="line">    x[i] &#x3D; ...;</span><br></pre></td></tr></table></figure></li><li>有些全局变量的插桩无意义  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int glob;</span><br><span class="line">int get_glob() &#123;</span><br><span class="line">    return glob; &#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="5-2-库处理"><a href="#5-2-库处理" class="headerlink" title="5.2 库处理"></a>5.2 库处理</h3><p>AddressSanitizer的当前实现基于编译时工具，因此不处理系统库（但是可以处理某些C库函数，例如memset）。 对于开源库，最好的方法可能是创建特殊的工具版本。 对于闭源库，可以使用静态/动态组合的方法。 所有可用的源代码都可以使用启用了AddressSanitizer的编译器来构建。 然后，在执行过程中，可以使用二进制翻译系统（例如DynamoRIO [7，6]）对闭源库进行检测。<br>&emsp;&emsp;可以仅使用运行时工具来实现AddressSanitizer，但是由于二进制翻译开销（包括次优的寄存器分配），它可能会变慢。 此外，尚不清楚如何使用运行时检测为堆栈对象实现重分区。  </p><h3 id="5-3-硬件支持"><a href="#5-3-硬件支持" class="headerlink" title="5.3 硬件支持"></a>5.3 硬件支持</h3><p>AddressSanitizer的性能特点适应于多数情况。但是，对大小很敏感的应用程序，当前的开销可能会过于严格。 AddressSanitizer执行的检测（请参见第3.2节）可以由单个新的硬件指令checkN（例如，用于4字节访问的“ check4 Addr”）代替。参数Addr的checkN指令应等效于<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ShadowAddr &#x3D;（Addr &gt;&gt; Scale）+ Offset; </span><br><span class="line">k &#x3D; * ShadowAddr; </span><br><span class="line">if（k！&#x3D; 0 &amp;&amp;（（Addr＆7）+ N&gt; k）</span><br><span class="line">    GenerateException（）;</span><br></pre></td></tr></table></figure><br>Offset和Scale的值可以存储在特殊的寄存器中，并在应用程序启动时进行设置。<br>&emsp;&emsp;这样的指令将通过减少icache压力来提高性能，结合简单的算术运算，并获得更好的分支预测，这也将显着减小二进制大小。<br>&emsp;&emsp;默认情况下，checkN指令可以是无操作且只能由特殊的CPU标志启用，从而可以选择性地测试某些执行甚至只测试寿命很长的进程的执行时间的一小部分。  </p><h2 id="6-结论"><a href="#6-结论" class="headerlink" title="6 结论"></a>6 结论</h2><p>在本文中，我们介绍了一种快速内存错误检测器AddressSanitizer。 AddressSanitizer查找越界（对于堆，堆栈和全局变量）访问和释放后重用的错误，平均速度降低了73％；该工具没有误报。<br>&emsp;&emsp; AddressSanitizer使用影子内存来提供准确和立即的错误检测。传统观点认为，影子内存会通过多级映射方案产生高开销，或者通过占用较大的连续内存而强加了过高的地址空间要求。我们新颖的影子状态编码可减少影子空间占用，让我们可以使用简单的映射（可以以较低的开销实现）。<br>&emsp;&emsp;该工具提供的高速度使用户可以更快地运行更多测试。该工具已用于测试Chromium浏览器，并在短短10个月内发现了300多个实际错误，其中包括一些可能导致安全漏洞的错误。AddressSanitizer用户在Firefox，Perl，Vim和LLVM中发现了错误。<br>&emsp;&emsp;AddressSanitizer所需的插桩非常简单，可以在各种编译器，二进制插桩系统甚至硬件中实现。  </p><h2 id="作者声明"><a href="#作者声明" class="headerlink" title="作者声明"></a><strong>作者声明</strong></h2><pre><code>本文版权归作者(rohex)所有，旨在技术交流使用。未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则相关责任自行承担。</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> 地址清洗 </tag>
            
            <tag> 地址消毒 </tag>
            
            <tag> 谷歌技术 </tag>
            
            <tag> fuzzing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习在二进制代码相似性分析中的应用</title>
      <link href="/2020/01/11/binianry-analysis-in-deep-learning/"/>
      <url>/2020/01/11/binianry-analysis-in-deep-learning/</url>
      
        <content type="html"><![CDATA[<h2 id="开篇"><a href="#开篇" class="headerlink" title="开篇"></a>开篇</h2><p>&emsp;&emsp;本文介绍了3篇二进制代码相似性分析的顶会技术，他们体现了二进制代码相似性分析中一些最先进的思想。第一篇是Genius技术，是在《基于神经网络图嵌入的跨平台二进制代码相似性检测》论文中作为对比技术介绍，它首次使用图嵌入这个机器学习的概念去做二进制代码相似性分析，它涉及到了聚类算法、图比对、密码本等技术，也为后两篇论文打下了基础；第二篇是Gemini技术，它使用了更先进的Structure2vec算法计算图嵌入，并融合Siamese网络和神经网络；第三篇是腾讯科恩实验室最近的顶会技术，它以Gemini的思路作为基础，使用了更多的自然言语处理和深度学习算法去训练程序控制流图中基本块语义信息、结构信息、顺序信息。</p><h2 id="开篇之后的白话"><a href="#开篇之后的白话" class="headerlink" title="开篇之后的白话"></a>开篇之后的白话</h2><p>&emsp;&emsp;最近，科恩实验室顶会<strong>《基于语义感知的神经网络的二进制代码相似度检测》</strong>让我眼前一亮。因为当时我也正尝试在二进制代码分析中引入机器学习，正在试用的是随机森林和adaboost算法（相较之下太low了），打算用它们做一个独立于IDA的func_split，用来识别二进制代码的函数。然后，就去看了一下这个论文，看上去很高大上。但郁闷的是，对提到的二进制相关知识都很熟悉，但对算法应用的原因和意义都很懵逼。就这样，深度学习在二进制分析上的应用让我产生了极大兴趣，我决定好好研究下。但是这个论文用的机器学习算法太多了，而且工作是基于另一篇论文的基础，为了搞懂这个论文，我决定先去读它的基线论文 <strong>《基于神经网络图嵌入的跨平台二进制代码相似性检测》</strong>，然后再来看看科恩顶会的创新和精妙之处 。  </p><h2 id="基于神经网络图嵌入的跨平台二进制代码相似性检测"><a href="#基于神经网络图嵌入的跨平台二进制代码相似性检测" class="headerlink" title="基于神经网络图嵌入的跨平台二进制代码相似性检测"></a>基于神经网络图嵌入的跨平台二进制代码相似性检测</h2><h3 id="从论文标题说起"><a href="#从论文标题说起" class="headerlink" title="从论文标题说起"></a>从论文标题说起</h3><ul><li><strong>图嵌入</strong><br>先解释一个最重要的术语“图嵌入”，图嵌入的目的是降维，在保留图特征的前提下将图经过非线性变换成一维向量。相较于以前通过比对两个二进制函数的CFG图（函数的控制流程图）的相似性去判断代码相似性（图比对），现在提取CFG图嵌入后对向量做相似性比较，其时间代价是不是更小，而且特征更为抽象。<br>&emsp;&emsp;但是，利用CFG图嵌入做二进制代码的相似性检测，前人已经做过了(Genius)，而且Genius在对CFG做嵌入之前，将CFG转换为ACFG，即提取控制流程图中平台无关的基本块属性和块间属性。Genius使用二部图匹配算法和密码本作为基础去计算ACFG的嵌入，具体做法是使用聚类算法训练出一个具有代表性的ACFG的特征向量集合，形成一个ACFG与特征向量对应的密码本，对于新的待计算ACFG，通过二部图匹配算法与码本中每个代表性的ACFG进行相似性比对，新ACFG的嵌入即为与其最相似的代表性ACFG的特征向量。Genius的图嵌入生成方法时间代价较高，而且码本质量取决于训练数据规模。<br>&emsp;&emsp;Gemini（论文实现的原型）采用Structure2vec算法计算ACFG的图嵌入，该算法从空间结构的相似性去定义相似度，通过评价函数整合节点和它n层邻居的信息，将这些信息压缩成一个有限维的非线性向量。<strong>原产的Structure2vec算法并不能直接用于计算ACFG图嵌入</strong>，Gemini使用了其变种，首先对ACFG每个节点使用变种的Structure2vec算法压缩基本块属性和图结构信息到一个特征向量中，然后使用聚合函数将所有节点的特征向量聚合成一个向量。听起来不错吧，<strong>它可以整合CFG中基本块信息和基本块间的结构信息，并把它们映射成一个非线性向量的表示形式。</strong>   <font size=2>注：Structure2vec论文是2017年发表，Genius论文是2016年发表，也不怪Genius没考虑到用Structure2vec算法去计算ACFG图嵌入。</font>   </li><li><p><strong>加入神经网络的图嵌入</strong><br>&emsp;&emsp;到这里，Gemini做二进制代码的相似性分析基础架构都有了（<em>即基于Structure2vec算法生成2个二进制函数的ACFG图嵌入，然后通过比较2个嵌入向量的相似性</em>），神经网络有什么用？这时，神经网络算法就该出场了，给它安排的活是训练Structure2vec算法的参数，这时候有公式可能更直观些。<br><img src="ainetwork5.png" alt=""><br>如公式2所示，这是Gemini选定用来在Structure2vec模型中做非线性映射的模型，这个非线性映射的输入xv是节点的基本块属性信息，u∈N(v)是节点的邻接节点信息，经过映射可得到一个节点的特征向量，而整个ACFG特征向量是通过所有节点聚合得来。其中，σ（·）是一个非线性变化， <strong>Gemini为了使非线性变化较为强大，就把σ（·）设计成n层全连接神经网络</strong>；W1是一个d*p矩阵，d是xv（基本块属性）的长度，p是生成的嵌入长度，W1也是待训练参数。<br>&emsp;&emsp;目前，总结来说就是，基础是Structure2vec模型中加入神经网络来训练其非线性变化的模型，再用聚合函数将ACFG节点的特征向量聚合成ACFG的图嵌入，结合神经网络的图嵌入最终输出的依然是ACFG图嵌入（也可以称为ACFG的特征向量）。   </p></li><li><p><strong>Siamese网络</strong><br>在前面已经介绍过本文采用的二进制代码相似比对的方式就是比较图嵌入，那么图嵌入计算出来后，如何处理可以得到相似度的结果，答案就是Siamese网络，其模型特点是在样本量少的情况下识别类型.<br><img src="ainetwork8.png" alt=""><br>如上图所示，Siamese模型本身包括了目标降维模块，正好上文的融入神经网络的图嵌入即可作为模型中的降维模块。整体模型的输入是两个待比较二进制函数的ACFG，经过嵌入网络得到降维的特征向量u1和u2，然后计算二者余弦距离，通过阈值判定结果是-1（非相似），还是1（相似）。当然，训练过程都有真实的标签，以便整个模型不断调整参数。  </p></li><li><strong>跨平台</strong><br>跨平台指的是什么呢？即，二进制代码相似性比较与二进制代码所处平台、使用的编译器和优化选项无关，训练出的ACFG图嵌入计算模型和使用的相似比对方法与以上条件无关。<br>又是如何做的呢？总结起来有两点工作：   <ol><li>继承了Genius提取二进制函数CFG中与平台无关性的属性，6个基本块属性：字符串常量、数字常量，传递指令数量，调用指令数量，运算指令数量，指令总数量；1个基本块间属性：基本块子代数量。需要注意的是，Gemini抛弃了Genius中使用的另一个基本块间属性“介数中心性”（betweenness），原因是该属性提取较慢，与模型的最终效果影响也不大。  </li><li>训练数据采集的平台无关性，Gemini使用同一份源码在不同系统平台、不同编译器、不同编译器优化选项的条件下生成大量带标签的样本。另外有一个样本处理的细节是<strong>不会将同一份源码编译后的二进制代码分开在训练集、验证集和测试集</strong>。个人认为这样做有助于在训练模型的过程中充分考虑到编译的不同条件，以训练出平台无关性模型。在测试时，也可以用其它源码生成的样本来验证未经训练的数据是否符合模型。 </li></ol></li><li><strong>总结标题</strong><br>在介绍了论文中的图嵌入、神经网络、跨平台的概念及论文中的应用，那论文整体的思路也都明确了。总结下标题，目标是做跨平台二进制代码的相似性检查，方法是加入神经网络的图嵌入。    <h3 id="对论文的思考"><a href="#对论文的思考" class="headerlink" title="对论文的思考"></a>对论文的思考</h3></li></ul><ol><li><strong>对于二进制代码，它的变化并不是无穷无尽的，因为它的产生是来源于机器规则，它看起来复杂难懂，但其内部必然藏着巨大的规律性</strong>，而深度学习的优势就在于挖掘这种潜在的规律，我目前认为“深度学习是只要你有，我就一定能挖出来”。至于怎么挖，用什么样的算法和模型，这需要人去建立二进制数据和模型的联系和关系，这篇论文是一个很好的结合，我相信未来，在这个方向上的继往开来者会很多。  </li><li>对于ACFG中的属性，不同平台、编译器、优化选项生成的二进制代码，<strong>有些属性值（运算指令、call指令、指令总数，甚至常量值等）存在噪声，它的成分并不是全部用来体现函数本身</strong>，有些仅是某个平台和编译器或优化选项特有的，例如一些安全机制，栈随机值保护、栈指针验证、异常处理等，在不同平台和优化选项中，这些可能出现，也可能不出现。训练模型时需要考虑这些，在模型真正用于实际时也需要考虑这些。  </li><li>论文写的非常好，从引言到原理阐述，其他方法的对比，对模型中特殊情况的考虑（例如超参问题），还有深度挖掘了这个项目的主线之外的价值点（例如再训练问题），并做了相关的实验。值得经常翻看，所以认真的把它翻译成了中文，包括人家的答谢，英文水平有限，还望有看到的见谅。<br><font color="FF0000" size=2>注：论文翻译可在博客的历史文章中找到</font>    <h2 id="基于语义感知的神经网络的二进制代码相似度检测"><a href="#基于语义感知的神经网络的二进制代码相似度检测" class="headerlink" title="基于语义感知的神经网络的二进制代码相似度检测"></a>基于语义感知的神经网络的二进制代码相似度检测</h2>现在来看看科恩的论文，着重说说它与Gemini的不同之处吧。<br><img src="tecent_paper_arch.png" alt="">    <h3 id="Semantic-aware-模块：BERT算法训练基本块语义与结构信息"><a href="#Semantic-aware-模块：BERT算法训练基本块语义与结构信息" class="headerlink" title="Semantic-aware 模块：BERT算法训练基本块语义与结构信息"></a>Semantic-aware 模块：BERT算法训练基本块语义与结构信息</h3>Gemini沿用了它的基线论文Genius提取CFG属性后（即ACFG）做图嵌入,该篇论文认为这将损失大量的语义信息，故而在形成类似Gemini中ACFG的过程前，引入了NLP（自然语言处理），即使用BERT算法对每个基本块序列进行训练，语义训练模型包含4个子任务，期望训练出的模型包含以下4个维度的信息：  <ul><li>Block的代码语义；  </li><li>Block的邻接信息；  </li><li>Block是否属于CFG；  </li><li>Block所属平台、编译器、及哪个优化选项。<br>语义提取模型最终输出类似于Genius和Gemini的ACFG图，区别是该部分使用机器学习替代了人工提取（使用IDA脚本），而且包含基本块属性额外的信息， <strong>输出的基本块特征向量由机器学习得到。</strong>   </li></ul></li></ol><h3 id="MPNN算法计算“ACFG”的图嵌入"><a href="#MPNN算法计算“ACFG”的图嵌入" class="headerlink" title="MPNN算法计算“ACFG”的图嵌入"></a>MPNN算法计算“ACFG”的图嵌入</h3><p>MPNN（消息传递网络）是由Google科学家提出的一种模型，它本质上还是利用卷积神经网络学习图结构信息，只是形式框架上较为新颖，它通过收到邻居的消息来更新自己的状态，所以叫作消息传递网络。（<em>目前还没有对卷积神经网络和MPNN进行细致学习，能理解的就是这么多，可能有不准确的地方</em>）。不过，简单的理解，该模型的作用可以类比Gemini的Structure2vec模型，他们的输入都是CFG图（其中基本块属性被量化成有限维特征向量），输出都是图嵌入， <strong>但这个图嵌入不是最终的图嵌入，它还要融入节点顺序模型的训练成果。</strong> </p><h3 id="CNN算法训练节点顺序的特征"><a href="#CNN算法训练节点顺序的特征" class="headerlink" title="CNN算法训练节点顺序的特征"></a>CNN算法训练节点顺序的特征</h3><p>使用CNN（卷积神经网络）对CFG中节点相应顺序或者说布局进行训练也是该论文的一个重要创新部分。由于前面已经包含了基本块的属性信息和CFG整体结构信息，这个模型就专注于训练CFG的节点顺序信息。具体做法是，先把CFG节点布局抽象成01矩阵，然后对矩阵做卷积神经网络，学习CFG节点顺序相关特征，最后输出是一个特征向量。   </p><h3 id="模型融合"><a href="#模型融合" class="headerlink" title="模型融合"></a>模型融合</h3><p>该篇论文使用了三个模型从不同角度去训练二进制代码CFG中的信息，其中语义感知模型和结构感知模型是串联的，顺序模型可以与前面两个并连，最后使用MLP（多层神经网络）将两条线上输出的特征向量映射为一个特征向量。 <strong>融入三种模型后输出的这个特征向量才是和Gemini中基于神经网络的Structure2vec模型训练出的特征向量是类似地位。</strong>  </p><h3 id="对论文的思考-1"><a href="#对论文的思考-1" class="headerlink" title="对论文的思考"></a>对论文的思考</h3><ol><li>科恩的论文对二进制本身特性考虑的更多，例如我在前边论文思考中提到的平台、编译器、优化选项产生的噪声，他们在语义感知模型中加入了训练Block属于某个平台、编译器和优化选项这个信息，不确定是否能消除这个噪声，但至少考虑到了；CFG还有一个很重要的信息，即节点的有向传播（ <strong>基本块间的跳转是有向的，不能逆代码流程方向传播</strong>），论文中的顺序感知模型也许正好可以弥补这个方面的信息。  </li><li>整个提取图嵌入的流程在3个地方用了神经网络算法，1个地方用了NLP算法，而且训练无法并行，也不是端到端， <strong>最长的链路为BERT -&gt; MPNN -&gt; MPL，这个也许会在实用性上面打些折扣，不知道是否可以做些合适的取舍或训练算法融合呢？</strong>  </li></ol><h2 id="感悟"><a href="#感悟" class="headerlink" title="感悟"></a>感悟</h2><p>在漏洞挖掘领域中，当一门新技术、一个新工具、一些新代码出现时，厉害的人往往可以收获一大批CVE，靠的是日益累积的技术能力和漏洞挖掘领域中敏锐的嗅觉。我看顶级研究也是靠这两样，以2016年Genius论文为基础，它使用了图比对和密码本去计算CFG图嵌入。到2017年Structure2vec论文出现时，Gemini能第一个想到用Structure2vec算法去替代图比对和密码本。BERT和MPNN也是2017年以后才出现的，科恩的论文能想到它们适应于解决ACFG人工生成问题和图嵌入计算的问题。 <strong>一个有前途的基础研究出来后，必定是遍地开花的结果，不过果实是留给准备充分的人！</strong>   </p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://acmccs.github.io/papers/p363-xuAemb.pdf" target="_blank" rel="noopener">Neural Network-based Graph Embedding for Cross-Platform</a>  </li><li><a href="https://keenlab.tencent.com/en/whitepapers/Ordermatters.pdf" target="_blank" rel="noopener">Semantic-Aware Neu for Binary Code Similarity Detection</a>  </li></ol><h2 id="作者声明"><a href="#作者声明" class="headerlink" title="作者声明"></a><strong>作者声明</strong></h2><pre><code>本文版权归作者(rohex)所有，旨在技术交流使用。未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则相关责任自行承担。</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> 神经网络 </tag>
            
            <tag> 图嵌入 </tag>
            
            <tag> 代码相似性 </tag>
            
            <tag> 二进制分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Neural Network-based Graph Embedding for Cross-Platform Binary Code Similarity Detection(翻译)</title>
      <link href="/2020/01/10/Neural-Network-based-Graph-Embedding-for-Cross-Platform/"/>
      <url>/2020/01/10/Neural-Network-based-Graph-Embedding-for-Cross-Platform/</url>
      
        <content type="html"><![CDATA[<h1 id="基于神经网络图嵌入的跨平台二进制代码相似性检测"><a href="#基于神经网络图嵌入的跨平台二进制代码相似性检测" class="headerlink" title="基于神经网络图嵌入的跨平台二进制代码相似性检测"></a>基于神经网络图嵌入的跨平台二进制代码相似性检测</h1><p>作者： Xiaojun Xu, …, 宋乐， 宋晓东</p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>&emsp;&emsp;跨平台二进制代码相似性检测的关键在于：<strong>检测二进制函数是否相似</strong>，它具有很多安全应用场景。例如，代码剽窃检测，恶意软件识别，搜索漏洞。现有方法依赖于近似图匹配算法，这种算法不可避免地速度慢，有时不准确，并且难以适应新任务。为了解决这些问题，在这项工作中，我们提出了一种基于神经网络计算嵌入层的新颖方法，即为每个二进制函数的控制流图计算数值向量，然后可以通过测量两个二进制函数的嵌入层距离来检测函数的相似性。我们实现了一个名为Gemini的原型。经过广泛评估，Gemini在相似度检测准确性方面大大优于最新技术。此外，Gemini可以将现有嵌入生成技术的时间缩短3到4个数量级，并将所需的训练时间从1周以上减少到30分钟至10小时。我们在实际的案例研究中表明，与Genius相比，Gemini可以识别出更多的脆弱固件镜像。我们的研究展示了深度学习在计算机安全问题上的成功应用。</p><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h2><p>&emsp;&emsp;给定两个二进制函数，我们想检测它们是否相似。 这个问题被称为“二进制代码相似性检测”，它在安全方面具有许多的应用场景，例如代码剽窃检测，恶意软件检测，漏洞搜索等。在这些场景中，<strong>物联网设备固件镜像中的漏洞搜索尤为重要</strong>，该问题比以往任何时候更加严峻。 源代码级别的单个错误可能会散布在数百个或更多具有不同硬件体系结构和软件平台的设备上。 崔等人[12]的研究表明，<strong>市场上80.4％发行的固件具有多个已知漏洞</strong>，并且许多最近发布的固件更新都包含第三方库中的漏洞，这些漏洞已经存在了八年之久。<br>&emsp;&emsp;安全从业人员越来越需要在多个平台（例如x86，ARM或MIPS）的二进制文件中快速直接地检测函数相似性。直到最近，研究人员才开始解决跨平台二进制代码相似性检测的问题[16、18、31]。这些工作提出直接从二进制代码中提取函数CFG中各节点的特征（足够鲁棒性的平台无关性特征）用来表征一个函数。然后，为了进行二进制代码相似性检测，使用图匹配算法来检查两个函数的CFG是否相似[16，31]。另一方面，Genius [18]从CFG中提取高级特征表征函数，并计算CFG的嵌入（即高维数值向量）。但是，要计算二进制函数的嵌入，它还依赖于图匹配算法来计算目标函数和二进制函数码本之间的相似度。<br>&emsp;&emsp;不幸的是，这种基于图匹配的方法具有两个不可避免的缺点。 首先，通过固定图匹配算法计算出的近似相似度函数很难适应不同的应用场景。 例如，在代码抄袭检测的场景中，给定两个仅在少数几个指令中有所不同的二进制代码，由于大多数代码是相同的，因此可以将它们视为相似。 但是在漏洞搜索的场景中，它们可能被认为是不同的，因为几个指令的差异可能会修复一个重要的漏洞。 <strong>人工设计的函数相似度检测本质上无法同时适用于两种情况</strong>。<br>&emsp;&emsp;其次，所有基于图匹配的相似性检测方法的效率都受到图匹配算法（例如二分图匹配）效率的限制。 但是，图形匹配算法很慢，即要求图形大小具有超线性运行时间。 因此，这种方法不可避免地效率低下。<br>&emsp;&emsp;近年来，深度学习[28]已应用于许多领域，包括二进制分析[42]，并且已显示出比其他方法更好的效果。 深度神经网络的优势在于，它们可以表示一个二进制分析任务，例如，为二进制函数生成一个嵌入，作为一个<strong>神经网络，其参数可以端到端地进行训练，因此它仅依赖于很少的领域知识</strong>（ 例如，先前方法中的图形匹配）。 此外，由于可以用不同的数据训练神经网络以适合不同的应用场景或任务，因此可以将基于深度神经网络的方法设计为自适应。 而且，可以有效地计算深度神经网络模型，即，运行时间与输入大小、网络大小呈线性关系。<br>&emsp;&emsp;受这些优点的启发，在这项工作中，我们提出了一种基于深度神经网络的方法来生成用于相似性检测的二进制函数的嵌入。特别是，假设二进制函数表示为一个控制流图（每个节点都有其附加的属性），则我们使用图嵌入网络将图转换为嵌入。以前，已经有人提出了图嵌入网络应用于一些领域（例如分子分类[13]）中的分类和回归任务。但是，我们的工作是相似性检测，这与分类不同，因此它们的方法不能直接应用于我们的任务。取而代之的是， <strong>我们提出了一种通过融合图嵌入网络和Siamese网络[7]来计算嵌入以进行相似度检测的新方法</strong>，该方法自然地抓住了两个相似函数的嵌入应该彼此接近的目的，反之亦然。然后可以对整个网络模型进行端到端训练，以进行相似性检测。<br>&emsp;&emsp;此外，我们使用默认策略设计了一种新的训练和数据集创建方法，以预先训练与任务无关的图形嵌入网络。 我们的方法 <strong>使用从相同源代码编译（但不同平台和编译器优化级别）的二进制函数构造大规模训练数据集</strong>。 我们的评估表明，与最新的基于图匹配的方法相比，这种与任务无关的模型更有效，并且可以更好地推广到未训练的函数[18]。<br>&emsp;&emsp;基于神经网络方法的一个优势是，可以在存在额外监督的情况下快速重新训练预训练模型，以适应新的应用场景。 我们的评估表明，在这种额外的监督下，重新训练的模型可以有效地适应新任务。  <strong>与以前的方法（例如Genius）不同，Genius需要花费一个多星期的时间来重新训练模型，而训练一个神经网络效率很高</strong>，并且每个再训练阶段都可以在30分钟内完成。 该效率特性使再训练在实际应用中成为可能，以提高相似性检测的性能。<br>&emsp;&emsp;我们已经实现了一个名为Gemini的原型。 我们的评估表明，在准确性和效率方面，Gemini都比Genius [18]等最先进的方法优越。 为了得到准确结果，我们将Gemini和Genius应用于相同任务：评估独立任务模型和特定任务模型。 对于前者，我们的预训练任务中独立模型的AUC（曲线下面积）为0.971，而Genius的AUC为0.913。 对于后者，从真实数据集中，我们的特定任务模型可以在前50个结果中比Genius平均多识别出25个脆弱固件镜像。 注意，以前的方法不能灵活地合并特定任务的有效监督。 因此，与以前的工作相比，<strong>再训练过程是我们方法的独特优势</strong>。<br>&emsp;&emsp;为了提高效率，在嵌入生成时间和训练时间方面，Gemini比Genius更有效率。 对于嵌入生成，Gemini比Genius方法快2400倍至16000倍。 对于训练时间，训练有效的Gemini模型所需的时间少于30分钟，而训练Genius所需的时间则超过一周。<br>&emsp;&emsp;在更广泛的范围内，这项工作展示了如何应用深度学习解决重要的和正在出现的计算机安全性问题的成功范例，并大大改善了最新成果。<br>我们将我们的贡献总结如下：   </p><ol><li>我们提出了第一种基于神经网络的方法来生成二进制函数的嵌入；  </li><li>我们提出了一种新颖的方法来使用Siamese网络训练嵌入网络，以便预先训练的模型可以生成嵌入以用于相似性检测；  </li><li>我们提出了一种再训练方法，以便预先训练的模型可以接受额外的监督以适应特定任务；  </li><li>我们实现了一个名为Gemini的原型。 我们的评估表明，在使用OpenSSL构建的测试集上，与Genius和其他基于图形匹配的先进方法相比，Gemini可以获得更高的AUC。  </li><li>我们的评估表明，Gemini相比现有技术（即Genius），可以将嵌入计算提高3到4个数量级。  </li><li>我们使用实际的固件镜像进行案例研究。 我们证明了使用Gemini，我们可以识别出比Genius更多的脆弱固件镜像。  </li></ol><h2 id="2-二进制代码相似性分析"><a href="#2-二进制代码相似性分析" class="headerlink" title="2 二进制代码相似性分析"></a>2 二进制代码相似性分析</h2><p>在本节中，我们首先以跨平台二进制代码搜索为例来说明设计相似性检测功能的问题。 然后，我们在解释现有方法的同时，还演示了有效的函数嵌入如何帮助设计检查函数相似性。 最后，我们介绍了使用神经网络作为生产函数嵌入的方法，以及这种方法的好处。   </p><h3 id="2-1-动力问题：-跨平台的二进制代码搜索"><a href="#2-1-动力问题：-跨平台的二进制代码搜索" class="headerlink" title="2.1 动力问题： 跨平台的二进制代码搜索"></a>2.1 动力问题： 跨平台的二进制代码搜索</h3><p>&emsp;&emsp;考虑跨平台二进制代码相似性检测的问题。 给定感兴趣的二进制函数（例如，包含Heartbleed漏洞的二进制函数），我们想检查大量的二进制函数语料库（例如，从各种IoT设备的固件镜像中提取的二进制函数），并快速准确地识别候选列表，在语义上与感兴趣的函数等效或相似。 <strong>我们将感兴趣的二进制函数称为查询函数，并将二进制函数的语料库称为目标语料库</strong>。<br>&emsp;&emsp;解决此问题的技术可以应用于许多安全场景，例如固件镜像中的漏洞搜索和二进制代码中的抄袭检测等。<br>&emsp;&emsp;这个问题的核心是设计一个功能来检测两个函数是否相似。 <strong>高效地解决此问题的需要实现以下设计目标：</strong>  </p><ul><li><strong>仅利用二进制：</strong>实际上，我们经常无法访问二进制函数的源代码。因此，高效的相似性检测和代码搜索技术必须可以直接应用于二进制代码。  </li><li><strong>跨平台支持：</strong>由于查询函数和目标语料库中的函数可能来自不同的硬件体系结构和软件平台，因此高效的二进制搜索技术必须容忍不同平台引入的语法变化并捕获这些二进制函数的内在特征。  </li><li><strong>高精准度：</strong>一个高效的二进制代码相似度检测器应该能够为一对类似函数分配高分，而为一对不相关函数分配低分。  </li><li><strong>高效率：</strong>应该为漏洞搜索系统和其他应用程序高效地计算相似度函数，以扩展到较大的目标语料库。  </li><li><strong>自适应：</strong>当领域专家可以提供相似或不相似的示例时，相似性功能应能够针对特定领域的应用快速适应这些示例。  </li></ul><h3 id="2-2-存在的技术"><a href="#2-2-存在的技术" class="headerlink" title="2.2 存在的技术"></a>2.2 存在的技术</h3><p>&emsp;&emsp;尽管在二进制代码匹配和搜索方面进行了一系列努力，但大多数工作仅针对单个平台的二进制代码[14，32]。<br>&emsp;&emsp;直到最近，研究人员才开始在跨平台的环境中解决这个问题。这些工作提出直接从二进制代码中提取各种特征，这些特征足够健壮，可以在不同的体系结构和编译器优化选项中持续存在。<br><strong>成对图匹配：</strong><br>&emsp;&emsp;Pewny等人提出[31]<strong>在CFG中为每个基本块提取输入-输出作为其特征（或标签），然后执行图匹配。</strong>不幸的是，这个过程代价非常高：输入输出的计算和图形匹配代价都很高。<br>&emsp;&emsp;为了提高效率，有人提出了discovRE [16]来提取更轻量级的语法级别特征（例如，运算指令的数量和调用指令的数量），而不是加快特征提取的速度，并在使用之前通过简单函数级别的特征进行预过滤图形匹配以提高搜索效率。然而，根据冯等人[18]：这种预过滤的方法是不可靠的，可能会导致搜索准确性的显著下降。从根本上讲，这两种方法都依赖于图匹配来检测相似性，这不可避免地效率低下。<br><strong>图形嵌入：</strong><br>&emsp;&emsp;为了同时实现可伸缩性和高精度，我们想从CFG中学习<strong>可索引的特征表示</strong>。换句话说，我们需要将图形编码为嵌入（即数字特征向量）。这样做，可以将相似度函数计算为两个向量之间的易于计算的距离函数，因此是有效的。同样， <strong>可以使用基于位置敏感哈希（LSH）的数据库对特征向量进行索引</strong>，以便可以在O（1）时间内执行搜索查询。<br>冯等[18]率先将这种方法应用于漏洞搜索问题。他们提出了Genius，一种图形嵌入工作流，如图1所示。<br><img src="ainetwork1.png" alt=""><br>给定二进制函数（从固件映像或已知漏洞），Genius首先以属性控制流程图（ACFG）的形式提取原始特征。在ACFG中，每个顶点都是标记有一组属性的基本块。表1列出了Genius中使用的六个块级属性和两个块间属性。<br><img src="ainetwork2.png" alt=""><br>图2说明了OpenSSL中包含Heartbleed漏洞函数的ACFG。然后将每个ACFG转换为高级嵌入，然后使用位置敏感哈希（LSH）将其存储到哈希表中。因此，要标识一组二进制函数是否与查询函数相似，我们只需要找到查询函数的相应嵌入，并在目标语料库中找到相似的嵌入。<br><img src="ainetwork3.png" alt=""><br>&emsp;&emsp;该流程的关键组成部分是如何将ACFG转换为其嵌入。 Genius采用基于密码本的方法来嵌入ACFG。 它使用一种聚类算法来训练一个密码本，该密码本由为每个群集标识的多个代表性ACFG组成。 然后，为了将ACFG转换为特征向量，Genius <strong>使用二部图匹配算法来测量指定ACFG与码本中每个代表性ACFG之间的相似性</strong>。 因此，这些相似性度量形成指定ACFG的特征向量。<br>&emsp;&emsp;虽然图形嵌入的想法令人鼓舞和令人信服，但<strong>使用密码本和图形匹配存在一些局限</strong>。 首先，码本生成是一个非常昂贵的过程，因为必须对训练数据集中的每对控制流图进行图匹配，然后才可以执行图聚类。 结果，所<strong>生成的码本的质量受到训练数据集规模的限制</strong>。 其次，图形嵌入的运行时间开销随代码簿的大小（即代码簿中控制流程图的数量）线性增加。 因此，码本的大小必须很小，1限制了图编码的保真度。 最后，但并非最不重要的一点是，这种方法的搜索精度最终受到二部图匹配质量的限制[35]。 作为一种近似算法，二部图匹配可能并不总是产生最佳匹配结果。    </p><h3 id="2-3-基于神经网络的嵌入生成"><a href="#2-3-基于神经网络的嵌入生成" class="headerlink" title="2.3 基于神经网络的嵌入生成"></a>2.3 基于神经网络的嵌入生成</h3><p>&emsp;&emsp;在本文中，我们建议采用一种基于神经网络的方法来嵌入ACFG，以克服以前基于图匹配的方法的局限性。 我们的方法采用神经网络将ACFG转换为嵌入。 我们将在第3节中讨论细节。这样做时，我们的方法比以前的工作有几个优点：<br><strong>更好的准确性：</strong><br>我们基于神经网络的嵌入可以比二部图匹配和Genius显着提高精度，这有两个主要原因。 首先，基于神经网络的图嵌入根本不依赖于二部图匹配。 取而代之的是，它通过迭代传播整个控制流图来评估整个图形表示形式。第二，<strong>神经网络中的参数为最大化嵌入目标而自动学习</strong>：两个相似的ACFG的嵌入之间的距离应该最小化，而两个异类ACFG的嵌入之间的距离应该最大化。此外，基于神经网络的方法允许在领域专家的额外监督下对模型进行重新训练，以更好地适应新的任务/场景，从而进一步提高准确性。<br><strong>嵌入效率更高：</strong><br>Genius中的图形嵌入计算非常慢，因为它必须与代码本中的每个ACFG进行二部图匹配。相比之下，我们的神经网络模型的计算成本较低。此外，神经网络中的所有计算都可以并行化，以利用大规模并行计算硬件（即多核CPU和GPU）。另一个性能提升来自不需要块间属性。为了获得良好的图形匹配结果，Genius提取了块间属性：offspring和betweenness的数量，与块级属性相比，计算代价平均要高8倍。另一方面，我们的神经网络模型只需要基本的块级属性和offspring数量（计算便宜）即可达到高精度。神经网络模型已经将块间关系信息整合到了嵌入中。因此，不需要这些块间属性（例如，betweenness）来实现高精度。<br><strong>更快的离线训练：</strong>为了计算密码本，Genius需要为大量训练ACFG计算距离矩阵，训练ACFG的时间复杂度在训练样本数量上是二次的，在二部图匹配算法的成本上是线性的。 相比之下，神经网络方法只需要训练恒定数量的时期，每个时期的时间复杂度与训练数据的大小呈线性关系。 结果，Genius花费了超过1周的时间来生成密码本，而我们的方法可以在30分钟内训练神经网络模型，这使得使用再次训练的实际应用成为可能。  </p><h2 id="3-基于神经网络模型的嵌入生成"><a href="#3-基于神经网络模型的嵌入生成" class="headerlink" title="3 基于神经网络模型的嵌入生成"></a>3 基于神经网络模型的嵌入生成</h2><p>&emsp;&emsp;我们首先在3.1节中介绍代码相似性嵌入问题，然后在3.2节中概述我们的解决方案。 然后，我们解释该方法的两个重要模块，即图嵌入网络和整体架构（第3.3节）以及训练方法（第3.4节）。 在第3.5节中将讨论如何通过预训练来获得与任务无关的模型，以及如何通过重新训练来获得与任务有关的模型。  </p><h3 id="3-1-代码相似性嵌入的问题"><a href="#3-1-代码相似性嵌入的问题" class="headerlink" title="3.1 代码相似性嵌入的问题"></a>3.1 代码相似性嵌入的问题</h3><p>&emsp;&emsp;如上所述，该代码相似性度量可以依赖于任务。 对于一个给定的任务，我们假设存在一个确定代码相似性度量的预言π，这是我们想学习的未知信息。 给定两个二进制程序函数f1，f2，π（f1，f2）= 1表示它们相似； 否则，π（f1，f2）= -1表示它们不相似。<br>&emsp;&emsp;在此，预言π特定于每个任务，通常是未知的。 在某些任务中，可以观察到有限数量的⟨f1，f2，π（f1，f2）⟩三重实例。 例如，领域专家可能能够提供有关预言π的一些真实数据。<br>&emsp;&emsp;代码相似性嵌入问题的目的是找到映射ϕ，将函数f的ACFG映射到矢量表示μ。直观地，这样的嵌入应该捕获足够的信息以检测相似函数。也就是说，给定易于计算的相似度函数Sim（·，·）（例如，两个向量的余弦函数），和两个二进制函数f1，f2：如果π（f1，f2）= -1，Sim（ϕ（f1），ϕ（f2））应该是较大值，否则是较小值。<br>&emsp;&emsp;学习嵌入（即，映射ϕ）的一个优点是它能够进行有效的计算。<strong>二进制函数之间的相似性可以使用代价较低的两个向量之间的相似性计算来代表</strong>，而不会产生代价高的图匹配算法的成本。<br>&emsp;&emsp;如前所述，使用神经网络去预测嵌入函数特别吸引人，因为当提供有限的与任务相关的真实数据时，可以快速地对其进行重新训练以轻松地适应给定任务。而且，计算基于神经网络的嵌入不依赖于任何昂贵的图匹配算法，因此可以有效地实现。  </p><h3 id="3-2-解决方法概述"><a href="#3-2-解决方法概述" class="headerlink" title="3.2 解决方法概述"></a>3.2 解决方法概述</h3><p>&emsp;&emsp;在本节中，我们阐述了解决代码相似性嵌入问题的关键思路。在这项工作中，我们假设函数f的二进制代码由其ACFG <em>g</em>表示。在下文中，我们将互换使用术语“ [函数的二进制代码]”和“ ACFG”。<br>&emsp;&emsp;我们将嵌入映射ϕ设计为神经网络。由于输入是ACFG，因此我们将利用机器学习社区中以前的图形嵌入网络来解决该问题[13]。但是，在Dai等人的工作中[13]，<strong>图形嵌入网络是针对分类问题而设计的</strong>，分类问题需要标签信息来训练模型。相反，我们的 <strong>代码相似性嵌入问题不是分类问题</strong>。因此，现有方法不能直接应用，我们需要设计一种新颖的方法来训练图嵌入网络来解决相似性检测问题。<br>&emsp;&emsp;为了应对这一挑战，我们<strong>提出了一种新的学习方法： 我们将训练ϕ，使之在区分两个输入ACFG之间的相似性方面表现出色，而不是预测任务上表现出色</strong>。特别是，我们设计了一个Siamese结构[7]，并将图形嵌入网络Structure2vec [13]嵌入其中。Siamese结构将两个函数作为其输入，并产生相似性得分作为输出。这使得模型可以进行以 <em>g1</em>， <em>g2</em> 作为输入，以及真实标签π（f1，f2）作为输出的有监督学习来进行端到端训练，而无需任何手工启发法方法去考虑嵌入如何被生成。因此，这种方法更健壮，更容易适应不同的任务。我们将在第3.4节中解释有关此总体架构和训练的更多详细信息。<br>训练Siamese结构需要大量成对的相似函数，以及成对的不相似函数。 但是，在大多数任务中，基本实际数据是有限的。 为了解决此问题，我们采取了一个默认策略，该策略将等效函数（即从相同源代码编译的二进制函数）视为相似，而非等效函数则不相似，因此在给定源代码集合的情况下，我们可以轻松生成大型训练集。 我们可以使用此数据集来预训练与任务无关的模型，该模型对于大多数任务都可以有效。 此外，为了合并针对特定任务少量可用的真实数据，我们的方法允许合并任务特定数据后对模型进行重新训练。 我们将在第3.5节中更详细地说明与<strong>任务无关的预训练和针对特定任务的再训练</strong>。  </p><h3 id="3-3-图嵌入网络"><a href="#3-3-图嵌入网络" class="headerlink" title="3.3 图嵌入网络"></a>3.3 图嵌入网络</h3><p>我们的图形嵌入网络由Dai等人的Structure2vec[13]改变而来。 将ACFG表示为<em>g=(V ，E)</em>，其中V和E分别是顶点和边的集合； 此外，图中的每个顶点v可以具有其他特征xv，它们对应于ACFG中的基本块特征。 图嵌入网络将首先为每个顶点v∈V计算一个p维特征μv，然后使用这些顶点嵌入的聚合计算g的嵌入向量μg。 即是μg：= Av∈V（μv），其中A是一个聚合函数，即求和或平均值。 在这项工作中，我们选择μg=∑v∈V（μv），并保留了使用其他聚合函数作为未来工作的探索。<br>&emsp;&emsp;在下文中，我们首先解释有关通用图嵌入网络的更多细节，然后介绍专门针对我们的ACFG嵌入问题实例化的变体。<br><strong>基础的Structure2vec方法：</strong> Structure2vec受到图形模型推理算法的启发，其中根据图拓扑g递归聚合顶点的特定特征xv。 经过几步递归后，网络将为每个顶点生成一个新的特征表示（或嵌入），同时考虑图形特征和顶点特征之间的相互作用。 更具体地说，我们将N（v）表示为图g中顶点v的邻居的集合。 然后，Structure2vec网络的一个变体会将每个顶点处的嵌入μv（0）初始化为0，并在每次迭代时将其更新为<br><img src="ainetwork4.png" alt=""><br>在此定点更新公式中，F是一个通用的非线性映射，我们将在以后指定选择。 根据更新公式，可以看到嵌入更新过程是基于图拓扑并以同步方式进行的。 仅在对上一轮的所有顶点进行的嵌入更新完成后，才会开始新一轮遍及各个顶点的嵌入。 显而易见，更新还定义了一个过程，其中顶点特征xv通过非线性传播函数F传播到其他顶点。此外，执行更新的迭代次数越多，顶点特征将传播到的距离越远处的顶点，并在远处的顶点上进行非线性聚合。 最后，如果在T迭代后终止更新过程，则每个嵌入μv（T）的顶点将包含有关其T跳邻域的信息，该信息由图拓扑和所涉及的顶点特征确定。<br>&emsp;&emsp;我们将学习这些参数，而不是在非线性映射F中手动指定参数。 为了训练最初设计用于分类问题的Structure2vec模型，先前的工作要求每个输入图g都具有真实性标签，以指示其属于哪个“类”，然后将该模型与Softmax层链接，以便可以通过最小化交叉熵损失来端对端地训练整个模型，如3.2节所述，该方法不适用于我们的情况，因为我们的问题不是分类问题。<br>&emsp;&emsp;取而代之的是，我们在Siamese结构中端到端的训练F中的参数与其他参数，Siamese结构使用这些嵌入来计算相似性，这在3.4节进行解释。<br> <img src="ainetwork7.png" alt=""><br><strong>对F的参数化：</strong>我们现在讨论使用神经网络对F参数化。图3展示了我们的网络结构。特别地，我们将F设计为具有以下形式：<br><img src="ainetwork5.png" alt=""><br>其中xv是图节点（或基本块）级特征的d维向量，W1是d×p矩阵，p是如上所述的嵌入大小。为了使非线性变换σ（·）更强大，我们将σ自身定义为n层全连接神经网络：<br><img src="ainetwork6.png" alt=""><br>其中Pi（i = 1，…，n）是p×p矩阵。我们将n称为嵌入深度。在此，ReLU是整流线性单位，即，ReLU（x）＝ max {0，x}。我们对更新函数F进行的新颖参数化以及第3.5节中描述的迭代更新方案完善了ACFG的嵌入网络。在算法1中概述了为每个ACFG生成嵌入的总体算法。在该算法中，W2是另一个p×p矩阵，用于转换嵌入向量。我们将其输出表示为ϕ（g）。  </p><h3 id="3-4-使用Siamese结构学习参数"><a href="#3-4-使用Siamese结构学习参数" class="headerlink" title="3.4 使用Siamese结构学习参数"></a>3.4 使用Siamese结构学习参数</h3><p>在本节中，我们阐述了整个网络体系结构的设计，该设计通过训练图嵌入来进行相似性检测。 特别是，我们将Siamese结构与图形嵌入Structure2vec网络结合使用。 Siamese结构使用两个相同的图形嵌入网络，即Structure2vec，它们在顶部连接。 每个图嵌入网络都将一个ACFG gi（i = 1，2）作为其输入，并输出嵌入ϕ（gi）。 Siamese结构的最终输出是两个嵌入的余弦距离。 此外，两个嵌入网络共享相同的参数集。 因此，在训练过程中，两个网络保持相同。 总体架构如图4所示。<br><img src="ainetwork8.png" alt=""><br>给定K对ACFG集合⟨gi，g’i⟩，具有真实配对信息yi∈{+1，-1}，其中yi = +1表示gi和g’i相似，即π（gi ，g’i）= 1，否则yi = -1。 我们将每对的Siamese网络输出定义为<br><img src="ainetwork9.png" alt=""><br>ϕ（g）由算法1产生<br>然后训练模型参数W1，P1，… 。 。 ，Pn和W2，我们将优化以下目标函数<br><img src="ainetwork10.png" alt=""><br>我们可以使用随机梯度下降来优化目标（3）。 根据图拓扑递归计算参数的梯度。 最后，一旦Siamese网络可以实现良好的性能（例如，使用AUC作为衡量标准），训练过程就会终止，并且训练后的图形嵌入网络可以将输入图转换为适合于相似性检测的有效嵌入。  </p><h3 id="3-5-独立任务预训练与特殊任务的再训练"><a href="#3-5-独立任务预训练与特殊任务的再训练" class="headerlink" title="3.5 独立任务预训练与特殊任务的再训练"></a>3.5 独立任务预训练与特殊任务的再训练</h3><p>训练模型需要关于预言π的大量数据，这可能很难获得。为了解决此问题，我们使用默认策略构造训练数据集。该数据集可用于预训练任务无关模型（对大多数常见任务有效）。当其他特定于任务的数据可用时，我们允许对预训练的模型进行快速重新训练以获取特定于任务的模型。我们在下面解释这两种方法。<br><strong>与任务无关的预训练：</strong>为了预训练适用于大多数常见任务的模型，直观地说，每个函数的生成嵌入应尝试捕获二进制函数在不同系统架构和编译器不变的特征。我们通过这样构建数据集来实现这种直觉：假设收集了一组源代码，我们可以使用不同的编译器和不同的优化选项将它们编译成针对不同体系结构的程序二进制文件。这样做时，默认的预测将认为，如果两个二进制函数是从相同的源代码编译而来的，则是相似的，否则非相似。为了构造训练数据集，对于每个二进制函数g，另一个相似的函数g1和一个不同的函数g2进行采样，以构造两个训练样本(g，g1，+1)和(g，g2，-1)。在我们的评估中（第4.2节），我们证明了使用此训练方法进行预训练的模型比使用基于[18]的相同任务的基于最新图形匹配的方法[18]的性能更好。<br><strong>特定于任务的再培训：</strong>有时，特定任务使用的策略可能会与用于预训练模型的默认策略有所不同。在这种情况下，我们需要一种有效的方法，通过使用领域专家提供的少量附加数据(f，f’，π（f，f’）)来微调图嵌入网络中的学习参数。 <strong>重新训练过程通过合入少量由领域专家提供的有关特定任务的附加数据来优化图形嵌入网络</strong>。<br>&emsp;&emsp;更具体地说，假设我们从人类专家那里获得了函数对（gi，g’i（的列表以及它们的真实标签π（gi，g’i），我们可以生成其他ACFG对以重新训练图嵌入网络ϕ（g）。特别是，对于提供的列表中的每个ACFG对gi，g’i，我们用配对信息yi =π（gi，g’i）对(gi，g’i)扩充训练集，这是来自人类专家。<br>&emsp;&emsp;使用此扩充的数据集，我们进一步训练了图嵌入网络几个（例如5个）时期。在每个时期中，新添加的对将比旧数据采样的频率更高（例如，采样频率提高50倍）。增强训练完成后，再训练网络φ（·）将被部署用于相似性检测任务。这种再训练过程允许人类专家向系统提供反馈，并且可以对模型进行微调以使其适应于特定于任务的预言π，从而进一步提高了相似性检测的准确性。  </p><h2 id="4-评估"><a href="#4-评估" class="headerlink" title="4 评估"></a>4 评估</h2><p>在本节中，我们将根据Gemini的搜索准确性和计算效率对其进行评估。另外，我们使用包含标签的数据集来评估独立任务的预训练模型的准确性。我们进一步使用真实数据集来研究，我们的模型如何进行重新训练以适应新任务。 在所有评估中，我们的方法都比最先进的方法更具优势[18]。  </p><h3 id="4-1-实验和装置"><a href="#4-1-实验和装置" class="headerlink" title="4.1 实验和装置"></a>4.1 实验和装置</h3><p>我们的系统由两个主要组件组成：ACFG提取器，用于得到图嵌入的神经网络模型。我们从Genius [18]的作者那里获得了<strong>ACFG提取器，它是反汇编工具IDA Pro[1]的插件</strong>，因此我们可以确保从二进制代码提取的原始特征与Genius提取的原始特征一致。我们在基于Python的TensorFlow [2]中实现了神经网络模型。<br>&emsp;&emsp;我们的实验是在装有两个Intel Xeon E5-2620v4 CPU（总共32个内核），运行于2.1GHz的服务器，96 GB内存，1TB SSD和8个GeForce GTX 1080 GPU卡上进行的。在训练和评估期间，仅使用了1个GPU卡。<br><strong>基线：</strong>以前有一些针对漏洞搜索问题的著作：discovRE [16]，Multi-HM和Multi-k-HM [31]，基于质心的搜索[10]和Genius [18]。冯等人已经证明，Genius方法比其他方法更准确，更有效[18]。因此，在我们的评估中，我们考虑了[18]中评估的两种基线方法。<br><strong>二部图匹配（BGM）：</strong>给定两个二进制函数，我们使用Genius中所述的二部图匹配直接在其ACFG上计算它们的相似性得分。该方法为评估成对图匹配方法的准确性提供了基线。<br><strong>基于代码本的GraphEmbedding（Genius）：</strong>这种方法为图形嵌入提供了基线。我们与Genius [18]的作者联系，并获得了ACFG提取代码和用于评估的代码本。为了比较，我们进一步实现了代码本生成和嵌入生成。<br><strong>数据集：</strong> 在评估中，我们收集了四个数据集：（1）数据集I，用于训练神经网络和评估预训练模型的准确性； （2）用于评估特定任务模型性能的数据集II； （3）效率评估数据集III； （4）案例研究的脆弱性数据集（数据集IV）。<br><img src="ainetwork11.png" alt="">  </p><ul><li><strong>数据集I：</strong>此数据集用于神经网络训练和基线比较。它由从源代码编译的二进制文件组成，因此我们有真实标签。也就是说，我们认为从相同的源代码函数编译的两个ACFG是相似的，而从不同的函数编译的两个ACFG是不相似的。特别是，我们使用GCC v5.4编译了OpenSSL（版本1.0.1f和1.0.1u）。编译器设置为在x86，MIPS和ARM中以优化级别O0-O3发出代码。我们总共获得18269个二进制文件，其中包含129365个ACFG。我们将数据集I分为三个不相交的功能子集，分别用于训练，验证和测试。统计信息显示在表2中。 在拆分期间，我们保证从同一个源函数编译的两个二进制函数不会在训练，验证和测试集之间分为两个不同的集。在此过程中， <strong>我们可以检查预训练的模型是否可以适应于看不见的函数</strong>。  </li><li><strong>数据集II：</strong>我们与Genius [18]的作者联系，以获取他们论文[18]中使用的相同的大规模数据集（在他们的论文中称为Dataset III），其中包括33,045个固件镜像。在这些镜像中，有8,128个可以成功解压缩。这些镜像来自26个不同的供应商的不同的产品，例如IP摄像机，路由器，访问站点等。  </li><li><strong>数据集III：</strong>为了评估效率，我们使用各种大小的ACFG（即，图中的顶点数）构造了一个数据集）。特别是，我们首先从数据集II中随机选择16个固件镜像。在这16个固件镜像中，有82,100个ACFG，大小从1到1,306。这些ACFG分为几组，以便同一组中的所有ACFG的大小均相同。对于包含20个以上ACFG的任何集合，我们从集合中随机选择20个，并删除所有其他ACFG。最后，我们在该数据集中获得了3,037个ACFG。  </li><li><strong>数据集IV：</strong>此数据集包含从[18]中的漏洞数据集获得的漏洞函数。总共包含154个易受攻击的函数。   </li></ul><p><strong>训练详情：</strong> 我们的神经网络模型首先使用数据集I进行如下预训练。我们使用Adam优化算法[27]，并将学习率设置为0.0001。我们将Siamese模型训练了100个时期。在每个时期，我们首先构造用于该时期的训练数据，如下所示：对于训练集中的每个ACFG g，我们从与g相同的源函数编译的所有ACFG的集合中，随机选择一个ACFG g1，并从中选择一个ACFG训练集中所有其他ACFG集中的g2。然后，我们生成两个训练样本：带有标签+1的(g，g1)和带有标签-1的(g，g2)。请注意，由于我们在每个时期分别为每个g随机选择g1和g2，因此训练数据通常在不同时期有所不同。在为每个时期生成训练数据后，在将其随机输入训练过程之前，将其随机打乱。每个小批量包含10对ACFG。在每个时期之后，我们在验证集上测量损失和AUC。在100个训练时期内，我们保存了在验证集上获得最佳AUC的模型。<br>&emsp;&emsp;默认情况下，嵌入大小p为64，嵌入深度n为2。模型运行T = 5次迭代。基本块属性包括块级属性和后代数目，即总共7个属性。  </p><h3 id="4-2-准确性"><a href="#4-2-准确性" class="headerlink" title="4.2 准确性"></a>4.2 准确性</h3><p>在本节中，我们评估了Gemini中预训练模型的准确性。为此，我们如下构建相似性测试数据集：从数据集I中的测试集中，对每个ACFG g，我们从测试数据集中随机选择两个ACFG g1，g2，这标签（g，g1⟩和⟨g，g2⟩分别为+1和-1（即来自同一源函数和不是来自同一源函数）。此相似性测试数据集包含26,265对ACFG。请注意，构造测试集是为了使从同一源代码编译的两个二进制函数不会同时出现在训练集和测试集中。这样，我们就可以检查Gemini在未训练的函数上的性能。图5a说明了我们的神经网络模型（Gemini）的ROC曲线以及两种基线方法。我们可以看到，双子座的表现大大超过BGM和Genius。<br>&emsp;&emsp;为了进一步检查Gemini在具有不同大小的图上的性能，我们将相似度-准确度测试集分为大图子集和小图子集。大图子集仅包含两个ACFG对，两个ACFG都至少具有10个顶点。小图子集包含其余部分。在大图子集和小图子集上评估的不同方法的ROC曲线分别绘制在图5b和图5c中。从这两个数字来看，我们有一致的观察结果：1）Gemini的表现明显优于BGM和Genius。 2）在小图上，Genius的性能优于BGM；在大图上，BGM的性能优于Genius；在大图和小图上，Gemini的性能均优于BGM和Genius。<br><img src="ainetwork12.png" alt="">  </p><h3 id="4-3-超参"><a href="#4-3-超参" class="headerlink" title="4.3  超参"></a>4.3  超参</h3><p>在本节中，我们评估了Gemini模型中超参数的有效性。特别是，我们研究了训练时期数量，嵌入深度，嵌入大小，ACFG属性和迭代次数的影响。训练时期数量的影响检查是使用相似性验证集。我们使用相似性测试集检查其他超参数。但是，在整个模拟测试集上，AUC值几乎相同。由于我们对模型在大型图上的性能更感兴趣，因此其他超参数的检查使用的是相似性测试集的大型图子集。<br><strong>训练时期数：</strong>我们训练了175个时期的模型，并每5个时期在验证集上评估模型的损失和AUC。结果绘制在图7a和图7b中。从图中可以看出，在经过5个训练周期后，损耗降至较低的值，然后几乎保持不变。模型训练了100个时期后，损失最小。我们对AUC值进行了类似的观察，尽管在模型训练了160个时期后出现了最高的AUC值。因此，我们得出结论，可以快速训练模型以实现合理的良好性能（5个时期后）。<br><strong>嵌入深度：</strong>我们在Gemini模型中改变函数σ中的层数。从图7c中，我们观察到当嵌入深度为2时，ROC曲线具有最大的AUC值。注意，原始的Structure2vec [13]可以看作是将嵌入深度选择为1。我们可以通过将一个非线性映射层增加到σ来观察到明显的改进。但是，添加更多的层并没有太大帮助。<br><strong>嵌入大小：</strong>在图7d中，我们可以看到实现最外面ROC曲线的嵌入大小为512。但是，与嵌入大小对应的所有曲线均不小于64。由于较大的嵌入大小需要更长的训练时间和更长的评估时间，因此将嵌入大小选择为64是在性能和​​效率之间的良好折衷。值得注意的是，即使我们选择嵌入尺寸为16，Gemini仍然比Genius（嵌入尺寸也为16）和BGM都更有效。<br><strong>ACFG属性：</strong>我们使用三种不同的方法来提取属性以构造ACFG，以评估准确性。特别地，我们认为属性包括（1）仅6个块级属性（Block）； （2）6个块级属性加上后代数量（块+ O）； （3）所有8个属性（块+ O + B）。从图7e中，我们观察到Block + O（总共7个属性）实现了最佳性能。这是出乎意料的，因为使用所有属性（Block + O + B）的模型应该比使用Block + O的模型更具表现力。我们认为这是培训数据的过度拟合场景。也就是说，在计算嵌入时，额外的betweeness属性会误导模型。<br><strong>迭代次数：</strong> 从图7f中，我们可以看到，当迭代次数T为5或更大时，该模型可获得最佳性能。 这是合理的，因为在此数据集中所有图的大小都大于10。它需要5跳才能将一个顶点上的局部信息传播到图的大部分。<br><img src="ainetwork13.png" alt="">   </p><h3 id="4-4-效率"><a href="#4-4-效率" class="headerlink" title="4.4 效率"></a>4.4 效率</h3><p>我们使用数据集III评估Gemini和Genius嵌入生成的效率。特别是，我们测量以下三个任务的等待时间：（1）一种函数的ACFG提取时间； （2）从ACFG到嵌入的生成时间； （3）嵌入生成的总延迟（包括任务1和任务2）。请注意，我们排除了使用IDA pro的反编译时间，因为这两种方法都相同。反编译二进制文件通常需要几秒钟的时间，可以对该二进制文件中的所有函数进行摊销。<br>&emsp;&emsp;对于嵌入生成，我们分别为Gemini和Genius实现了多个版本。我们在Tensorflow中实现了Gemini的CPU和GPU版本。这样，我们可以最大程度地利用多核硬件来提高性能。对于Genius，我们实现了单线程版本和多线程版本。由于Genius使用二部图匹配将ACFG的嵌入计算为该ACFG与码本中每个图之间的相似性得分，因此可以自然地并行化它，以便每个线程处理码本中的一个图。多线程版本将这些计算并行化。<br><strong>ACFG提取时间：</strong>图6a（每个样品一个点）和图6b（不同ACFG大小的平均提取时间）说明了结果。我们可以观察到，仅提取6个基本块属性以及提取6个基本块属性以及子代数属性需要相似的时间，但是如果我们另外提取介于中间属性，则平均要花费8倍的时间。从图6b中，我们可以看到提取时间通常随ACFG大小的增加而增加，但变化很大。请注意，Genius需要所有8个属性才能实现其最佳性能。相比之下，Gemini可以通过嵌入更新的迭代来聚合图结构信息，从而可以实现最佳性能，而无需进行昂贵的块间属性计算。因此，Gemini在ACFG提取方面可以比Genius平均提高8倍。<br><strong>嵌入生成时间：</strong>嵌入生成时间如图6c和图6d所示。我们可以观察到，Gemini的CPU实现比Genius的多线程版本快2400倍至16000倍。平均而言，加速可以高达7000倍。我们将此归因于几个原因。首先，Gemini方法避免了昂贵的图形匹配算法，并将时间复杂度降低到图形中边的数量。由于ACFG是稀疏图形，即每个顶点的出度最多为2，因此计算成本几乎与图形大小成线性关系。其次，Gemini方法中的大多数计算都可以实现为矩阵运算：矩阵乘法，矩阵求和以及矩阵上的逐元素运算。所有这些操作都可以并行化，以利用底层的多核CPU来实现内核数量方面的加速。另一方面，Genius中的图匹配算法不容易并行化。唯一的加速来自并行处理码本中的每个元素，因此这种加速受码本中元素数量的限制。稍后，我们的分析将表明，在Genius中很难达到理论上的加速上限，即码本大小。<br>&emsp;&emsp;现在我们比较Genius的单线程版本和多线程版本，并表明很难达到加速的理论上限，即码本大小。尽管多线程版本的运行速度可以提高10倍，但平均速度仅为35％。一个原因是，当Genius中使用的密码本包含一个具有超过500个顶点的大图形时，当处理的ACFG较小时，处理此元素的时间将占总特征生成时间的主导。此外，多线程同步引入了额外的开销。图6c和图6d支持此观察结果：（1）当ACFG较小时，多线程版本与单线程版本相似，甚至更慢； （2）当ACFG变大时，多线程的速度也会提高。<br>&emsp;&emsp;我们进一步检查了Gemini在GPU上的性能。但是，我们发现GPU版本平均比CPU版本慢10％。这主要发生在小图的嵌入生成上。在较大的图表上，GPU版本的运行速度比CPU版本快70％。我们将此观察结果归因于以下事实：GPU版本需要额外的开销，即在计算之前分配GPU内存并将数据从主内存复制到GPU内存。因此，随着ACFG的增大，与计算嵌入的总时间相比，此开销微不足道。<br><strong>嵌入生成的总体延迟：</strong> Genius的嵌入生成时间包括块级和块间函数（即图6a中的Block + O + B）的ACFG提取时间，以及函数嵌入生成的多线程CPU实现（即Genius（M ），如图6c）所示。对于Gemini，嵌入生成时间包括用于块级功能的ACFG提取时间和后代的数量（即，图6a中的Block + O）以及图形嵌入的CPU实现（即，图6c中的Gemini（CPU）） ）。我们观察到双子座可以实现27.7倍至11625.5倍的加速比。平均而言，Gemini的运行速度比Genius快386.4倍。<br><img src="ainetwork14.png" alt="">  </p><p><font size=2 ><strong>图6：对数据集III的效率评估。 图6a和图6c绘制了数据集III中每个样本的一个点。 在图6b和图6d中，我们平均所有具有相同ACFG大小的数据点的运行时间。 因此，在这两张图中，每个ACFG大小都有一个数据点。 在图6a和图6b中，“块”表示6个块级属性的提取时间； “ + O”表示提取还包括子代数属性； “ + B”表示提取还包括中间属性。 在图6c和图6d中，Gemini（CPU）和Gemini（GPU）分别表示Gemini方法的CPU和GPU实现。 Genius（S）和Genius（M）分别表示Genius的单线程和多线程实现。</strong></font></p><h3 id="4-5-训练时间"><a href="#4-5-训练时间" class="headerlink" title="4.5 训练时间"></a>4.5 训练时间</h3><p>尽管离线训练时间被大量的在线查询来摊销，但新固件镜像的发布可能需要以每月为基础甚至每周一次为基础更新学习模型，以更准确地对数据建模。因此，我们简要比较Genius和Gemini的训练时间。<br>&emsp;&emsp;Genius方法需要使用一种称为频谱聚类的无监督学习算法来计算密码本。该算法需要构造一个距离矩阵，该距离矩阵生成的时间复杂度代价是训练数据大小的二次方。结果，当训练数据包含100,000个函数（在我们先前的实验中用于构建密码本）时，Genius花费了一个多星期的时间来构建密码本。<br>&emsp;&emsp;相比之下，由于Gemini模型仅运行固定数量的时期，因此其运行时间与时期数量成线性关系，并且与每个时期（即训练数据集）中的样本数量呈线性关系。在我们的实验中，每个时期包含大约206,000个训练样本，并且运行时间不到5分钟。先前我们已经证明了Gemini模型仅需要训练5个时期即可达到合理的性能，而运行100个历元可提供最佳性能。这意味着，Gemini需要不到30分钟（5个时期）的时间来训练模型，使其性能超过Genius，而达到最佳性能则需要不到10小时。因此，我们基于神经网络的方法比Genius允许更频繁地更新模型。该属性对于使重新训练和模型更新切实可行至关重要。</p><h3 id="4-6-理解嵌入"><a href="#4-6-理解嵌入" class="headerlink" title="4.6 理解嵌入"></a>4.6 理解嵌入</h3><p>我们将使用任务独立的预训练嵌入网络使嵌入计算可视化，以了解其有效性。特别是，我们随机选择5个函数源代码，并使用不同的编译器，不同的目标体系结构和不同的优化级别来计算相应二进制函数的嵌入。然后，我们使用t-SNE [46]将高维嵌入投影到二维平面上。我们在图8中绘制投影点，不同的源函数以不同的颜色表示。我们可以观察到：（1）从同一源函数编译的二进制函数彼此接近； （2）从不同的源函数编译的二进制函数彼此相距甚远。因此，该可视化说明我们独立于任务的预训练嵌入功能可以在嵌入中保留源函数的信息，而与目标体系结构，使用的编译器和优化级别无关。<br><img src="ainetwork15.png" alt="">  </p><h3 id="4-7-使用真实数据集对特定任务再训练的准确度"><a href="#4-7-使用真实数据集对特定任务再训练的准确度" class="headerlink" title="4.7 使用真实数据集对特定任务再训练的准确度"></a>4.7 使用真实数据集对特定任务再训练的准确度</h3><p>在本节中，我们使用实际的固件镜像评估特定于任务的再培训方法的有效性。评估的配置方法与[18]相同。我们在数据集II中提取了函数的ACFG，总共得到420,558,702个函数。我们从数据集IV中进一步选择了两个漏洞，与[18]中使用的漏洞相同。对于每个漏洞，我们认为在包含相同漏洞的数据集I中搜索尽可能多的函数是一项特定的任务。为了实现这一目标，我们从数据集I上进行预训练的模型中重新训练模型。<br>&emsp;&emsp;为了与[18]（仅检查前50个最相似的结果）进行比较，我们还评估了前50个函数之间的精度。结果展示，通过重新培训，Gemini可以在前50个结果中为每个任务实现80％以上的准确度，这明显优于其精度在20％到50％左右的现有技术[18]。我们在下面介绍细节。总体而言，我们的方法允许从前50个结果中的Genius中平均识别出25个以上新的易受攻击的固件镜像。<br><strong>再训练效果：</strong>我们以迭代方式进行再培训。首先，我们有一个预先训练的模型，并使用它来计算目标语料库中所有函数的嵌入，以建立索引。在这种情况下，每个查询可以在3秒内处理完毕。我们手动检查前K个（例如K = 50）结果，并为每个结果分配真实标签，以便将前K个结果用于再训练。重新训练的每次迭代之后，我们重新计算从整个目标语料库中随机采样的子集（例如10％）的嵌入，以获得新的top-K结果列表。我们重复此过程几次迭代。在实践中，我们的实验表明，我们只需要很少的重复训练。请注意，Genius方法不能灵活地有效地合并此<strong>类额外监督</strong>。因此，再培训过程是我们方法相对于Genius的独特优势，并允许我们的方法在领域专家的额外监督下达到更高的准确性。<br>&emsp;&emsp;特别是，由于Genius [18]提供了参考结果，因此我们使用与Genius中相同的两个漏洞，即CVE-2015-1791和CVE-2014-3508。对于CVE-2015-1791，我们发现仅进行了1次迭代再培训，我们的方法就从前50个结果中找到了来自四个供应商（例如D-Link，ZyXEL，DD-wrt和Shibby by Shibby）的42个存在镜像的漏洞。此外，在前100个结果中，我们的方法发现了85个真实肯定。这些结果表明，一次重新训练迭代有助于将精度提高到84％以上。作为参考，Genius仅能检测到14个易受攻击的固件镜像（精度为28％），并且仅来自D-Link和Belkin。<br>&emsp;&emsp; <strong>CVE-2014-3508较难，因为控制流程图在补丁之前或之后不会更改，而是仅再插入一条指令</strong>（即将零值存储到内存缓冲区中）作为补丁。使用我们的方法，经过3次重复训练，我们的方法在前50个结果中发现了41个固件镜像，这些镜像是易受攻击的，其精度为82％。相比之下，Genius只能识别前50个结果中的24个易受攻击的固件镜像（精度为48％）。<br><strong>再培训时间：</strong>就时间消耗而言，对于每次迭代，我们将模型重新训练5个时间段，并采样整个数据集的10％进行评估（如前所述）。注意，在第二步中，不需要重新生成ACFG，因此我们只需要消耗嵌入计算的成本。对于每次迭代，这两个自动化步骤的总时间可以在2小时内完成。在人工调查时间方面，我们发现经验丰富的专家可以在2小时内完成50名候选函数的人工打标签。对于以后的迭代，此时间甚至可以更短，因为在进行第一次迭代之后，专家们已经很熟悉易受攻击的代码。总体而言，人类专家花了不到12个小时的时间进行了3次迭代，以针对给定的漏洞训练有效的模型。将模型部署到整个数据集后，大约需要12个小时才能为整个数据集生成嵌入。因此，我们得出结论， <strong>我们方法的再训练能力使人类专家的反馈得以实际使用，从而在合理的时间内（即一天之内）提高了搜索准确性</strong>。  </p><h2 id="5-相关工作"><a href="#5-相关工作" class="headerlink" title="5 相关工作"></a>5 相关工作</h2><p>在整篇文章中，我们已经讨论了密切相关的工作。在本节中，我们简要地调研了其他相关工作。我们将重点放在使用代码相似性来搜索没有源代码的已知bug的方法。查找未知bug的其他方法[3、8、9、34、42–44]将不在本节中讨论。对于基于机器学习的bug搜索[18]，我们已经在本文前面讨论了比较。<br><strong>基于原始功能的错误搜索：</strong>许多研究人员已经致力于解决二进制文件中的bug搜索问题，并为该方向做出了巨大贡献。从根本上说，它们依赖于直接从二进制文件中提取的各种原始特征来进行代码相似性匹配。 N-gram或N-perms [26]是bug搜索的两种早期方法。他们采用二进制序列或助记符代码匹配，而不了解代码的语义[25]，因此他们不能兼容由不同编译引起的操作码重新排序问题。为了进一步提高准确性，<strong>基于跟踪的方法[14]将执行序列捕获为代码相似性检查的函数</strong>，可以解决操作码更改问题。 TEDEM [32]使用表达式树为每个基本块捕获语义。但是，操作码和寄存器名称在整个体系结构中是不同的，因此这两种方法不适合在跨体系结构中查找bug。<br>&emsp;&emsp;许多其他方法可用于跨体系结构设置中的bug搜索，但是将其用于大规模固件bug搜索则很昂贵。 Zynamics BinDiff [15]和BinSlayer [6]采用昂贵的图同构算法来量化控制流图之间的相似度以进行代码搜索。 BinHunt [20]和iBin-Hunt [29]中使用的符号执行和定理证明者设计昂贵，因为它们需要提取方程式并进行等效检查。<br>&emsp;&emsp;虽然皮尼等[31]使用MinHash来减少代码相似度的计算，他们的图匹配算法仍然太昂贵，无法处理数百万个图对。 DiscovRE [16]利用预过滤通过消除不必要的匹配对来增强基于CFG的匹配过程，但是预过滤不可靠，并且会输出大量的假阴性[18]。许多其他方法，例如Costin等。文献[11]在大规模搜索bug时确实有效，但它们仅针对具有明显伪像的特定bug而设计，无法处理更一般的情况。<br><strong>图形嵌入：</strong>图分析在各种实际应用中具有重要意义，例如生物学[13]和社交网络[19]。通常，图嵌入在图分析中使用有两种不同的意图：第一个是嵌入图的节点，这意味着找到从节点到向量空间的映射，以便保留图的结构信息[21]。在早期方法中，LLE [36]找到了嵌入向量，因此节点的嵌入是其附近节点的线性组合。在[4]中，当两个节点之间的边缘权重较大时，两个节点的嵌入彼此接近。最近，基于深度学习的方法被用于处理大规模图形数据集。<br>&emsp;&emsp;本文采用的图嵌入的另一种意图：找到一个代表整个图的嵌入向量。之后，人们可以在其上执行机器学习方法来处理诸如蛋白质设计和基因分析之类的任务[39]。当前，内核方法[38]被广泛用于处理结构数据，如序列[17]和图形[5]。<br>&emsp;&emsp;内核方法的关键是精心设计的内核函数（节点对之间的正半定函数）。通过计算图中显示的基本结构来设计一类内核。例如，[33]计算图中的特定子树模式； [41]计算具有特定大小的子图的外观；在[40]中，在称为Weisfeiler-Lehman算法的过程中将计算不同的结构。但是，在这些方法中，内核在学习之前是固定的，因此嵌入空间的尺寸可能非常大。<br>&emsp;&emsp;另一类内核利用了以下事实：图形模型可以考虑带有噪声和变化的结构化数据。两个代表性的例子是Fisher核[23]和概率乘积核[24]。这些内核适合输入图的图形模型，并在分布之间使用某种形式的内部积作为内核函数。我们在论文中使用的模型Structure2vec [13]，也为输入图构造了图形模型，并通过神经网络对图形模型的推论算法进行参数化，以定义相应内核函数的特征。<br><strong>基于深度学习的图嵌入方法：</strong> Scarselli等人提出了第一个图神经网络来计算图的嵌入[37]。 Li等。使用门控循环单元（GRU）扩展[37]来生成特征。戴等人使用原则性的图形模型思维来概括这两项工作，从而可以定义更灵活的嵌入功能[13]。<br>&emsp;&emsp;因此，我们使用[13]的变体作为嵌入生成函数。从大型网络（例如社交网络）生成图形嵌入还有另一项研究[22、30、45、47]。这些工作着重于无监督学习或半监督学习以及生成图中不同节点的特征，而不是整个图的嵌入。使用这些方法，将其他训练数据合并到再训练中也不容易，这是它们不适合我们的原因。</p><h2 id="6-结论"><a href="#6-结论" class="headerlink" title="6 结论"></a>6 结论</h2><p>在本文中，我们提出了一种基于深度神经网络的方法来生成二进制函数的嵌入。 我们实现了一个名为Gemini的原型。 我们的广泛评估表明，在相似度检测准确度，嵌入生成时间和总体训练时间方面，Gemini比最新技术要优秀得多。 我们在现实世界中的案例研究表明，与最新技术（即Genius）相比，使用再培训Gemini可以识别出更多的脆弱性固件镜像。  </p><h2 id="答谢"><a href="#答谢" class="headerlink" title="答谢"></a>答谢</h2><p>我们感谢匿名评论者的有用评论。 感谢Chenxinyun对本文撰写的帮助。 该材料部分基于美国国家科学基金会在TWC-1409915、1664315、1719175，IIS-1350983，IIS-1639792和SaTC-1704701，ONR在N00014-15-1-2340，DARPA下的授权下支持的工作 适用于FA8750-15-2-0104和FA8750-16-C-0044，伯克利Deep Drive，NVIDIA，Intel和Amazon AWS。 本材料中表达的任何观点，发现，结论或建议均为作者的观点，不一定反映美国国家科学基金会的观点。  </p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>[1] 2015. The IDA Pro Disassembler and Debugger. <a href="http://www.datarescue.com/" target="_blank" rel="noopener">http://www.datarescue.com/</a><br>idabase/. (2015).<br>[2] Martín Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et al. TensorFlow: A system for large-scale machine learning.<br>[3] Thanassis Avgerinos, Sang Kil Cha, Alexandre Rebert, Edward J Schwartz, Maverick Woo, and David Brumley. 2014. Automatic exploit generation. Commun. ACM 57, 2 (2014), 74–84.<br>[4] Mikhail Belkin and Partha Niyogi. 2002. Laplacian eigenmaps and spectral<br>techniques for embedding and clustering. In Advances in neural information<br>processing systems. 585–591.<br>[5] Karsten Michael Borgwardt. 2007. Graph kernels. Ph.D. Dissertation. lmu.<br>[6] Martial Bourquin, Andy King, and Edward Robbins. 2013. BinSlayer: accurate comparison of binary executables. In Proceedings of the 2nd ACM SIGPLAN Program Protection and Reverse Engineering Workshop.<br>[7] Jane Bromley, Isabelle Guyon, Yann LeCun, Eduard Sickinger, and Roopak Shah.<br>1993.Signature Verification Using A “Siamese” Time Delay Neural Network. In NIPS.<br>[8] Sang Kil Cha, Maverick Woo, and David Brumley. 2015. Program-adaptive mutational fuzzing. In Oakland.<br>[9] Daming D. Chen, Manuel Egele, Maverick Woo, and David Brumley. 2016. Towards Automated Dynamic Analysis for Linux-based Embedded Firmware. In NDSS.<br>[10] Kai Chen, PengWang, Yeonjoon Lee, XiaoFengWang, Nan Zhang, Heqing Huang, Wei Zou, and Peng Liu. 2015. Finding Unknown Malice in 10 Seconds: Mass Vetting for New Threats at the Google-Play Scale. In USENIX Security.<br>[11] Andrei Costin, Jonas Zaddach, Aurélien Francillon, and Davide Balzarotti. 2014. A large-scale analysis of the security of embedded firmwares. In USENIX Security.<br>[12] Ang Cui, Michael Costello, and Salvatore J Stolfo. 2013. When Firmware Modifications Attack: A Case Study of Embedded Exploitation.. In NDSS.<br>[13] Hanjun Dai, Bo Dai, and Le Song. 2016. Discriminative Embeddings of Latent<br>Variable Models for Structured Data. In International Conference on Machine Learning.<br>[14] Yaniv David and Eran Yahav. 2014. Tracelet-based code search in executables.<br>In Proceedings of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation.<br>[15] Thomas Dullien and Rolf Rolles. 2005. Graph-based comparison of executable objects (English version). SSTIC 5 (2005), 1–3.<br>[16] Sebastian Eschweiler, Khaled Yakdan, and Elmar Gerhards-Padilla. 2016. discovRE: Efficient Cross-Architecture Identification of Bugs in Binary Code. In<br>Symposium on Network and Distributed System Security (NDSS).<br>[17] Eleazar Eskin, Jason Weston, William S Noble, and Christina S Leslie. 2003.<br>Mismatch string kernels for SVM protein classification. In Advances in neural information processing systems. 1441–1448.<br>[18] Qian Feng, Rundong Zhou, Chengcheng Xu, Yao Cheng, Brian Testa, and Heng<br>Yin. 2016. Scalable Graph-based Bug Search for Firmware Images. In ACM Conference on Computer and Communications Security (CCS’16).<br>[19] Linton C Freeman. 2000. Visualizing social networks. Journal of social structure 1, 1 (2000), 4.<br>[20] Debin Gao, Michael K Reiter, and Dawn Song. 2008. Binhunt: Automatically finding semantic differences in binary programs. In Information and Communications Security.<br>[21] Palash Goyal and Emilio Ferrara. 2017. Graph Embedding Techniques, Applications, and Performance: A Survey. arXiv preprint arXiv:1705.02801 (2017).<br>[22] Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In Proceedings of the 22nd ACM SIGKDD international conference on<br>Knowledge discovery and data mining. ACM, 855–864.<br>[23] Tommi S Jaakkola, Mark Diekhans, and David Haussler. 1999. Using the Fisher<br>kernel method to detect remote protein homologies.. In ISMB, Vol. 99. 149–158.<br>[24] Tony Jebara, Risi Kondor, and Andrew Howard. 2004. Probability product kernels. Journal of Machine Learning Research 5, Jul (2004), 819–844.<br>[25] Md Enamul Karim, Andrew Walenstein, Arun Lakhotia, and Laxmi Parida. 2005.<br>Malware phylogeny generation using permutations of code. Journal in Computer<br>Virology 1, 1-2 (2005), 13–23.<br>[26] Wei Ming Khoo, Alan Mycroft, and Ross Anderson. 2013. Rendezvous: A search<br>engine for binary code. In Proceedings of the 10th Working Conference on Mining<br>Software Repositories.<br>[27] Diederik Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).<br>[28] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. 2015. Deep learning. Nature<br>521, 7553 (2015), 436–444.<br>[29] Jiang Ming, Meng Pan, and Debin Gao. 2012. iBinHunt: binary hunting with<br>inter-procedural control flow. In Information Security and Cryptology. Springer,<br>92–109.<br>[30] Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 701–710.<br>[31] Jannik Pewny, Behrad Garmany, Robert Gawlik, Christian Rossow, and Thorsten<br>Holz. 2015. Cross-Architecture Bug Search in Binary Executables. In 2015 IEEE<br>Symposium on Security and Privacy (Oakland’15). IEEE.<br>[32] Jannik Pewny, Felix Schuster, Lukas Bernhard, Thorsten Holz, and Christian<br>Rossow. 2014. Leveraging semantic signatures for bug search in binary programs.<br>In ACSAC.<br>[33] Jan Ramon and Thomas Gärtner. 2003. Expressivity versus efficiency of graph kernels. In Proceedings of the first international workshop on mining graphs, trees and sequences. 65–74.<br>[34] Alexandre Rebert, Sang Kil Cha, Thanassis Avgerinos, Jonathan Foote, David<br>Warren, Gustavo Grieco, and David Brumley. 2014. Optimizing Seed Selection<br>for Fuzzing. In USENIX Security.<br>[35] Kaspar Riesen and Horst Bunke. 2009. Approximate graph edit distance computation by means of bipartite graph matching. Image and vision computing 27, 7 (2009), 950–959.<br>[36] Sam T Roweis and Lawrence K Saul. 2000. Nonlinear dimensionality reduction<br>by locally linear embedding. science 290, 5500 (2000), 2323–2326.<br>[37] Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and<br>Gabriele Monfardini. 2009. The graph neural network model. IEEE Transactions<br>on Neural Networks 20, 1 (2009), 61–80.<br>[38] Bernhard Schölkopf and Alexander J Smola. 2002. Learning with kernels. 2002.<br>(2002).<br>[39] Bernhard Schölkopf, Koji Tsuda, and Jean-Philippe Vert. 2004. Kernel methods in computational biology. MIT press.<br>[40] Nino Shervashidze, Pascal Schweitzer, Erik Jan van Leeuwen, Kurt Mehlhorn,<br>and Karsten M Borgwardt. 2011. Weisfeiler-lehman graph kernels. Journal of<br>Machine Learning Research 12, Sep (2011), 2539–2561.<br>[41] Nino Shervashidze, SVN Vishwanathan, Tobias Petri, Kurt Mehlhorn, and Karsten Borgwardt. 2009. Efficient graphlet kernels for large graph comparison. In Artificial Intelligence and Statistics. 488–495.<br>[42] Eui Chul Richard Shin, Dawn Song, and Reza Moazzezi. 2015. Recognizing<br>Functions in Binaries with Neural Networks.. In USENIX Security. 611–626.<br>[43] Yan Shoshitaishvili, Ruoyu Wang, Christophe Hauser, Christopher Kruegel, and Giovanni Vigna. 2015. Firmalice-Automatic Detection of Authentication Bypass Vulnerabilities in Binary Firmware.. In NDSS.<br>[44] Nick Stephens, John Grosen, Christopher Salls, Andrew Dutcher, and Ruoyu<br>Wang. 2016. Driller: Augmenting Fuzzing Through Selective Symbolic Execution.<br>In NDSS.<br>[45] Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei.<br>2015.Line: Large-scale information network embedding. In Proceedings of the<br>24th International Conference on World Wide Web. InternationalWorld WideWeb Conferences Steering Committee, 1067–1077.<br>[46] Laurens Van Der Maaten. 2014. Accelerating t-SNE using tree-based algorithms. Journal of machine learning research 15, 1 (2014), 3221–3245.<br>[47] Zhilin Yang, WilliamWCohen, and Ruslan Salakhutdinov. 2016. Revisiting semisupervised learning with graph embeddings. arXiv preprint arXiv:1603.08861 (2016).   </p><h2 id="作者声明"><a href="#作者声明" class="headerlink" title="作者声明"></a><strong>作者声明</strong></h2><pre><code>本文版权归作者（rohex）所有，旨在技术交流使用。未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则相关责任自行承担。</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> 神经网络 </tag>
            
            <tag> 图嵌入 </tag>
            
            <tag> 代码相似性 </tag>
            
            <tag> 漏洞检测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>rop链攻击原理与思路(x86/x64)</title>
      <link href="/2020/01/04/rop-link-exploits/"/>
      <url>/2020/01/04/rop-link-exploits/</url>
      
        <content type="html"><![CDATA[<h2 id="rop链的基础原理"><a href="#rop链的基础原理" class="headerlink" title="rop链的基础原理"></a>rop链的基础原理</h2><ul><li>rop是Return Oriented Programming（面向返回的编程）的缩写；</li><li>根据函数调用规则，当刚跳转到其它函数去执行时，<strong>从被调用者的视角看：栈顶是返回地址，紧接着是自己的参数</strong>（X86架构下）；  </li><li>然后，被调用者会对栈空间进行一系列操作，保存寄存器和存储临时变量，但在即将退出时会清理自己消耗的栈空间，以使其回到自己被调用前的栈空间，<strong>保持栈平衡</strong>；  </li><li>最后，被调用者<strong>以ret指令结尾</strong>，ret指令将栈顶地址传递到IP寄存器，随后<strong>代码也就跳转到之前栈顶存放的返回地址处</strong>；  </li><li>rop链即是基于以上这个简单的原理，在代码空间中寻找以ret结尾的代码片段或函数（代码片段称为Rop gadgets），组合可以实现拓展可写栈空间、写入内存、shell等功能，<strong>依靠ret将代码执行权紧握在自己的手里</strong>;</li><li>早期的ret2libc原理也是基于ret，如下payload：libc_system函数地址位置处于存在栈溢出函数被调用前的栈顶，溢出函数执行完后，就会跳到这个地址开始执行，下一个地址大小是libc_system函数执行完的返回地址，在下一个地址大小开始是libc_system函数的参数。   </li></ul><pre><code>```payload = &quot;A&quot;*n + p32(libc_system) + p32(final_ret) + arg_addr + ...```</code></pre><h2 id="构造rop链的实例（x86）"><a href="#构造rop链的实例（x86）" class="headerlink" title="构造rop链的实例（x86）"></a>构造rop链的实例（x86）</h2><ul><li><p>漏洞特征<br><strong>描述：</strong> 假如存在这样一个漏洞：造成了栈溢出，可以溢出数个地址大小，至少能覆盖掉ret返回地址（EIP）和后面需要布置的一些参数空间。<br><strong>环境：</strong>ubuntu 16.04 32， 开了ASLR、DEP，关闭CANNARY，目标代码不基址随机化，plt和got表项中存在write或print等可以打印地址的函数，有目标机器的libc.so</p></li><li><p>利用思路：</p><ol><li>payload1：跳转到write或print函数（plt处代码），构造参数使其打印got表中某项地址，并在地址泄露任务完成后跳回存在溢出的函数，使其可以被再次利用；  </li><li>搜寻libc.so中system函数的地址和字符串”/bin/sh”，使用泄露地址与其相应偏移算出system函数和”/bin/sh”的真实加载地址；</li><li>payload2: 填充ret地址处system函数加载地址，并为其布置”/bin/sh”地址作为参数;</li><li><p>get shell，exploits如下所示：   </p><p><img src="rop_link_exploits1.png" alt="">  </p></li></ol></li><li><p>无目标机器的libc.so的情况下<br>利用pwntools里的DynELF泄露system函数地址。如下，其实就是写一个泄露一个地址大小的函数：<strong>输入一个地址，打印这个地址中存储的值（大小也为一个地址大小），并且保证可以被无数次调用</strong>，大部分DynELF泄露地址姿势都如此。  </p><p> <img src="rop_link_exploits2.png" alt=""></p></li></ul><h2 id="构造rop链的实例（x64）"><a href="#构造rop链的实例（x64）" class="headerlink" title="构造rop链的实例（x64）"></a>构造rop链的实例（x64）</h2><ul><li><p>x64指令在栈空间操作的变化有两个：   </p><ul><li>地址变成了64位;</li><li>函数传参从x86的栈传递变成寄存器传递，前6个参数分别使用rdi、rsi、rdx、rcx、r8、r9，多于6个的参数使用栈传递。  </li></ul></li><li><p>漏洞特征<br><strong>描述：</strong> 栈溢出，可以溢出数个地址大小的空间。<br><strong>环境：</strong>ubuntu 16.04 64， 开了ASLR、DEP，关闭CANNARY，目标代码不基址随机化，plt和got表项中存在write或print等可以打印地址的函数，有目标机器的libc.so。 </p></li><li><p>利用思路</p><ol><li>搜索gadget1：可以实现写参数到rdi、rsi、rdx，然后调用write函数泄露libc地址；</li><li>利用泄露libc的函数真实地址与system和”/bin/sh”中的偏移计算system和”/bin/sh”真实加载地址；</li><li>再利用gadgets1是rdi指向libc中的”/bin/sh”，然后跳转到system地址执行。</li></ol></li><li><p>实例调试</p><h3 id="泄露libc地址"><a href="#泄露libc地址" class="headerlink" title="泄露libc地址"></a>泄露libc地址</h3><ul><li><p>linux x64下通用的构造参数的gadget，__libc<em>csu_init函数是linux运行库重要函数，在可执行程序执行之前执行，它里面正好有一段可以用来传递参数+跳转到任意地址执行的超级gadget，\</em>_libc_csu_init函数gadgets片段如下图所示：<br><img src="rop_link_exploits3.png" alt="">  </p><p>1) gadget1从标记1处开始，把栈顶数据依此弹出到rbx、rbp、r12、r13、r14、r15d；<br>2) gadget2从标记2处开始，会把r13、r14、r15d中的数据分别赋值到rdx、rsi、edi，其中r15d和edi分别表示r15和rdi的低32位空间，所以到此为止可以控制函数的前三个参数值；<br>3) 到地址0x40060处时，gadget2虽然完成了寄存器参数的布置，但还没有ret结束掉这个gadget，所以还会往下执行；<br>4) 3处会使用上面3条指令传递好的参数去执行某函数，函数地址是r12+rbx<em>8处存的值，由于r12和rbx也可以在gadget1中被控制，在此处将[r12+rbx</em>8]指向write函数地址就可以实现地址泄露；<br>5) 3处执行完地址泄露后，由于无ret指令不能返回我们可以控制的地址中去，再往下看到4处当rbx不等于rbp时会跳到gadget2处不断打印刚才泄露的地址，因此我们需构造rbx==rbp，这样就会再次执行gadget1，然后通过ret返回到下一次漏洞函数，等待第二个payload。<br>到目前为止我们可以实现地址泄露，将rbx构造为0，那么rbp为1时可以从gadget1执行进入gadget2，那么r12中存入write函数在got表中地址，可在gadget2的3处执行地址打印，因此构造如下payload：<br>payload1 = ‘A’<em>offsets + p64(0)#rbx值 + p64(1)#rbp值 + p64(got_write) + p64(8)#write函数第3个参数 + p64(got_write)#write函数第2个参数,泄露的地址 + p64(1)#write函数第1个参数 + p64(gadget2) + ‘A’</em>56 + p64(main)<br>调试该payload，在0x400609处下断点：<br>断下时寄存器值已经变成我们想要的，如下图所示：<br><img src="rop_link_exploits4.png" alt=""><br>r12中是即将要跳转的打印函数，打印函数的fd、addr、size也已经布置好，最终泄露的地址如下：<br><img src="rop_link_exploits5.png" alt="">   </p></li></ul></li></ul><h3 id="找到合适的”-bin-sh”"><a href="#找到合适的”-bin-sh”" class="headerlink" title="找到合适的”/bin/sh”"></a>找到合适的”/bin/sh”</h3><p>通过上面可以看到libc中的”/bin/sh”地址为0x7f42f5e3ed57，而我们利用的gadget只能控制rdi的低32位，放不下”/bin/sh”的完整地址，因此无法用libc中泄露的”/bin/sh”。<br>由于目标函数没有aslr，且地址空间的高32位为0，因此可以写入”/bin/sh”到目标代码的.bss段。<br>    payload2=’A’<em>0x58 + p64(gadget1) + p64(0) + p64(1) + p64(got_read) + p64(16) + p64(bss_addr) + p64(0) + p64(gadget2) + ‘A’</em>56 + p64(main)<br>如下图，成功将”/bin/sh”写入目标代码的bss段：<br>  <img src="rop_link_exploits6.png" alt="">  </p><h3 id="利用bss段的”-bin-sh”和泄露的system函数地址，执行shell"><a href="#利用bss段的”-bin-sh”和泄露的system函数地址，执行shell" class="headerlink" title="利用bss段的”/bin/sh”和泄露的system函数地址，执行shell:"></a>利用bss段的”/bin/sh”和泄露的system函数地址，执行shell:</h3><p> 改写一下payload2后一段，使其执行完后，不跳转到main函数，而是直接调转到system函数：<br> 如果想利用400609 call    qword ptr [r12+rbx<em>8]跳转到system，那么需要将system函数写入某个内存中，并将r12+rbx</em>8指向该内存，改写一下payload2使其一次性写入system地址和”/bin/sh”;执行完写后，再次通过gadget1将存放”/bin/sh”的bss地址传递到rdi，存放system_addr的bss地址传递到r12，如下：<br>    payload2=’A’*0x58 + p64(gadget1) + p64(0) + p64(1) + p64(got_read) + p64(16) + p64(bss_addr) + p64(0) + p64(gadget2)\  </p><pre><code> + &#39;A&#39;*8 +  p64(0) + p64(1) + p64(bss_addr) + p64(0) + p64(0) + p64(bss_addr+8) + p64(gadget2) + ...      p.send(p64(system_addr) + &quot;/bin/sh\x00&quot;)  </code></pre><p> 写入system地址和”/bin/sh”时的断点：<br>  <img src="rop_link_exploits7.png" alt=""><br> system地址写到了bss_addr，”/bin/sh”写到了bss_addr+8位置。<br>再此执行到gadget2中时：<br>   <img src="rop_link_exploits8.png" alt=""><br>r12+rbx*8 == r12 == 0x601040 指向system函数，而RDI指向字符串”/bin/sh”，万事俱备;往下执行即可以获得shell：  </p><p><img src="rop_link_exploits9.png" alt="">    </p><h2 id="作者声明"><a href="#作者声明" class="headerlink" title="作者声明"></a><strong>作者声明</strong></h2><pre><code>本文版权归作者（rohex）所有，旨在技术交流使用。未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则相关责任自行承担。</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> 漏洞 </tag>
            
            <tag> Rop Chain </tag>
            
            <tag> CTF </tag>
            
            <tag> 栈溢出 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pwn工具简介</title>
      <link href="/2020/01/03/linux-exploits-tools/"/>
      <url>/2020/01/03/linux-exploits-tools/</url>
      
        <content type="html"><![CDATA[<h2 id="pwntools"><a href="#pwntools" class="headerlink" title="pwntools"></a>pwntools</h2><p>pwntools是一个为CTF PWN题而开发的python库，可用来与本地目标或远程目标交互，生成符合编码的shellcode和payload，解析和搜寻elf文件，还有一个可以做内存泄漏的DynELF模块。<br>（1）基础信息返回函数、符号虚拟地址（也许不真实，可以用来求相对偏移），可访问ELF文件中如字典信息：<br><img src="linux-exploits-tools1.png" alt=""><br>例如下例代码可访问plt表中write函数地址：<br>    elf = ELF(‘stackoverflow’)<br>    plt_write =  elf.plt[‘write’]  </p><p>（2）可搜索字符串，返回的是生成器，例如下例代码返回libc.so.6文件字符串迭代器：<br>    libc = ELF(‘libc.so.6’)<br>    libc.search(‘/bin/sh’)   </p><p>（3）DynELF是pwntools中专门用来应对无libc情况的漏洞利用模块。<br><img src="linux-exploits-tools3.png" alt=""></p><h2 id="peda"><a href="#peda" class="headerlink" title="peda"></a>peda</h2><p>PEDA是为GDB设计的一个强大的插件，它扩展了gdb命令，提供额很多人性化的功能，比如高亮显示反汇编代码、寄存器、内存信息，提高了debug的效率。  </p><ol><li>安装：<br> git clone <a href="https://github.com/longld/peda.git" target="_blank" rel="noopener">https://github.com/longld/peda.git</a> ./peda<br> echo “source ./peda/peda.py” &gt;&gt; ~/.gdbinit</li></ol><ol><li><p>使用 </p><ul><li>vmmap查看内存映射<br><img src="linux-exploits-tools6.png" alt=""></li><li><p>checksec<br>查看目标程序的漏洞利用缓解措施 </p></li><li><p>pattern<br>生成字符串模板 写入内存 用于定位溢出点</p></li><li><p>searchmem pattern start end<br>查找libc库里的 “\bin\sh”<br><img src="linux-exploits-tools7.png" alt=""></p></li><li><p>查找gadgets<br><img src="linux-exploits-tools8.png" alt=""></p></li></ul></li></ol><h2 id="ROPgadget"><a href="#ROPgadget" class="headerlink" title="ROPgadget"></a>ROPgadget</h2><p>1.peda的rop搜索到的rop gadgets较少，该专业工具可识别更多的gadget。<br><img src="linux-exploits-tools9.png" alt="">  </p><h2 id="pwndbg"><a href="#pwndbg" class="headerlink" title="pwndbg"></a>pwndbg</h2><p>待更新…</p><h2 id="作者声明"><a href="#作者声明" class="headerlink" title="作者声明"></a><strong>作者声明</strong></h2><pre><code>本文版权归作者(rohex)所有，旨在技术交流使用。未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则相关责任自行承担。</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> 漏洞 </tag>
            
            <tag> ctf </tag>
            
            <tag> writeup </tag>
            
            <tag> exploits </tag>
            
            <tag> tools </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux漏洞利用思路</title>
      <link href="/2020/01/03/linux-exploits-ideas/"/>
      <url>/2020/01/03/linux-exploits-ideas/</url>
      
        <content type="html"><![CDATA[<h2 id="栈溢出-rop链"><a href="#栈溢出-rop链" class="headerlink" title="栈溢出-rop链"></a>栈溢出-rop链</h2><p>待更新…</p><h2 id="堆漏洞利用"><a href="#堆漏洞利用" class="headerlink" title="堆漏洞利用"></a>堆漏洞利用</h2><ol><li><p><strong>普通溢出</strong>：溢出多个字节，覆盖下一个chunk结构，造成unlink<br>first chunk溢出覆盖second chunk的size、fd、bk，将size覆盖为0；释放first chunk时，ptmalloc会通过second chunk的尾部（通过second chunk size字段寻址）定位到second chunk下一个chunk的presize字段；通过second下一个chunk的prevsize判断second是否为空闲chunk，由于此时定位的prevsize即是被覆盖为0的second chunk size，因此ptmalloc判断second chunk为空闲，由此发生向前合并，并发生second chunk的unlink。</p></li><li><p><strong>off by one</strong>：伪造chunk，溢出prevsize和size，造成unlink<br>在first chunk中伪造一个fake chunk，并溢出覆盖second chunk size的PREV_IN_USE flag 为0，将prevsize改为伪造的size；那么释放掉second chunk时，就会发生向后合并，并发生fake chunk的unlink。</p></li><li><p><strong>off by one</strong>：溢出prevsize为较大值，修改size的PREV_IN_USE，伪造向后合并的pre chunk size（house of einherjar，由 Hiroki Matsukuma 提出）<br>把seconde chunk的 size 位的 PREV_IN_USE flag 改为0，prev_size 改为一个自己想要的值，free 掉第二个 chunk 的时候就会连带着把前面的一大片空间（自己伪造的 prev_size）给 unlink 掉（伪造合适的 fd 和 bk 来绕过 unlink 的 check！），然后合并成一块更大的 chunk，放入 bin 里面，下一次 malloc 的时候就能 malloc 到那块空间，然后就能覆盖那块空间上原有的内容（数组指针、函数指针等等）。</p></li><li><p><strong>double free思路</strong>：第一次free一个chunk后，得到一个野指针指向堆的空闲内存区域；申请内存覆盖该区域，伪造两个连续的chunk，第二个chunk以野指针为chunk的起始地址；第二次释放该chunk，造成两个伪造chunk的向后合并，造成第一个fake chunk的unlink。（unlink加入一个检测double free的机制：如果该chunk块的下一个chunk size的PREV_IN_USE flag 为0，那释放该chunk会引发异常，如下图）<br><img src="linux-exploits-ideas.png" alt="">  </p></li><li><strong>UAF思路</strong>：释放一个chunk后没有将指针置NULL（存在野指针），导致后面有机会可以向该内存写入数据；假如后面申请内存的chunk head在野指针控制范围内，可以修改chunk的head，使释放时发生unlink。  </li><li><p><strong>fastbins思路</strong>（chunk属于fastbins管理，利用需存在堆漏洞，fastbins无unlink时对双向链表的检查）  </p><ul><li><p>Double free造成任意内存指针分配：<br>a.假如fastbins上存在2个chunk，fastbins链表结构为：fastbins[i]-&gt;  chunk2 -&gt; chunk1（最近释放的chunk指针放在fastbins中管理）；<br>b.再次释放chunk1（double free），那么chunk1的指针被写入fastbins[i]，chunk1的fd也指向chunk2，链表结构为：fastbins[i]-&gt;  chunk1 -&gt;  chunk2 -&gt; chunk1；<br>c.如果此时malloc掉chunk1，然后伪造fd指针到fake chunk，再malooc掉chunk2，chunk1，那么fake chunk的指针会被写到fastbins;d.再次malloc将会分配该块地址（fake chunk，可以是任意空间）。</p></li><li><p>House of Spirit：<br>覆盖一个fast chunk的fd，使其指向可控的区域，只要构造好数据，释放后系统会错误的将该区域作为空闲chunk放到相应的fast bin里面，最后再分配出来的时候，就可能将目标区域分配给用户。</p><font size=2 color="FF0000">注：fastbins使用单项链表管理空闲chunk，只是用fd指针；fastbins数组中存放的是链表尾指针；每当malloc时，返回fastbins数组里chunk指针，更新为返回chunk的fd；每次free一个fast chunk时，chunk放到链表尾（fd指向当前chunk链表最后一个chunk），更新fastbins数组chunk链表尾指针。</font></li></ul></li><li><p>Topchunk （House Of Force）<br>a.覆写top chunk的size为一个较大值（可以是(unsigned long) -1)），这样可以绕过是否大于用户申请大小的检查；b.申请一个chunk，可以使top chunk切分后，更新的top chunk指针指向目标区域；再次申请时就可以申请到目标区域。</p></li></ol><ol><li><p>任意地址free漏洞<br>free一片可控地址空间，在该地址空间伪造chunk，使释放时发生unlink。</p></li><li><p>unlink的注意事项：<br>由于glibc增加了unlink的校验，目前只能导致一次固定地址写，<font color="FF0000">伪造 fd 和 bk 的时候需要某个地址存放有有指向该 chunk 的指针</font>，而且这个地址不会因为 ASLR 随机化并且是可写的，满足这两个条件的话一般来说只有 binary 的 bss 段了。如果在堆上的话那么就需要首先 leak 堆地址，其他同理。</p></li></ol><h2 id="内核漏洞利用"><a href="#内核漏洞利用" class="headerlink" title="内核漏洞利用"></a>内核漏洞利用</h2><p>待更新…</p><h2 id="作者声明"><a href="#作者声明" class="headerlink" title="作者声明"></a><strong>作者声明</strong></h2><pre><code>本文版权归作者(rohex)所有，旨在技术交流使用。未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则相关责任自行承担。</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> 漏洞 </tag>
            
            <tag> ctf </tag>
            
            <tag> writeup </tag>
            
            <tag> exploits </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>漏洞利用缓解措施</title>
      <link href="/2020/01/03/linux-exploits-ease-methods/"/>
      <url>/2020/01/03/linux-exploits-ease-methods/</url>
      
        <content type="html"><![CDATA[<h2 id="操作系统安全防护"><a href="#操作系统安全防护" class="headerlink" title="操作系统安全防护"></a>操作系统安全防护</h2><ol><li><p>ASLR<br>ASLR(Address space layout randomization，地址空间布局随机化)通过随机放置数据区域的地址空间来防止攻击者跳转到内存的特定位置。在windows上ASLR主要包括堆栈随机化、PEB与TEB随机化、映像随机化，windows系统上虽然xp时代就提出来了，但是从vista开始ASLR才真正发挥作用。在linux上ASLR主要包括栈地址随机化、LIBS/MMAP随机化、EXEC随机化、BRK随机化、VDSO随机化。在没有ASLR的情况下让程序跳转到一个已经存在的系统函数的漏洞利用方式被称为ret2libc。  </p><ul><li>栈地址随机化:2.6.15内核开始支持。</li><li>2LIBS/MMAP随机化:程序每次执行动态库都被加载到不同的内存位置。2.6.15内核开始支持。</li><li>EXEC随机化:程序每次执行都将加载到不同的内存位置。可以这么理解，LIBS/MMAP随机化相当于windows中dll的随机化，而EXEC随机化相当于windows中exe的随机化。</li><li>BRK随机化:linux系统中brk和mmap这两个系统调用用来分配内存。当brk ASLR关闭的时候，start_brk和brk都是指向bss段的尾部的；当brk ASLR开启的时候，start_brk和brk初始位置是bss段的尾部加一个随机的偏移。2.6.26内核开始支持。</li></ul></li><li><p>DEP 堆栈不可执行</p></li></ol><h2 id="编译器安全防护"><a href="#编译器安全防护" class="headerlink" title="编译器安全防护"></a>编译器安全防护</h2><ol><li><p>Built as PIE<br>前面说了EXEC的随机化，实际上更准确的说法是PIE(Position Independent Executables，位置无关可执行文件)。PIE只有在系统开启ASLR和编译时开启-fpie -pie选项这两个条件同时满足时才会生效。最初因为在像x86这样通用寄存器较少的架构上PIE的性能损失比较明显，所以并不是所有的程序都启用了PIE。从Ubuntu 17.10和Fedora 23开始为所有的架构都启用了PIE。</p></li><li><p>Built with RELRO<br>RELRO(RELocation Read-Only，只读重定位)让加载器将重定位表中加载时解析的符号标记为只读，这减少了GOT覆写攻击的面积。RELRO可以分为Partial RELRO(部分RELRO)和Full RELRO(完整RELRO)。开启Partial RELRO的话GOT表是可写的；开启FULL RELRO的话GOT表是只读的。从Fedora 23开始所有软件包都已启用了Full RELRO。开启-Wl,-z,relro选项即可开启Partial RELRO；开启-Wl,-z,relro,-z,now选项即可开启Full RELRO。</p></li><li><p>Stack Protector<br>Stack Protector又名canary，stack cookie……等等，类似于VS编译器中的GS。gcc4.2中添加了-fstack-protector和-fstack-protector-all编译参数以支持该功能，gcc4.9中添加了-fstack-protector-strong编译参数让保护的范围更广。 </p></li></ol><h2 id="新型防护技术"><a href="#新型防护技术" class="headerlink" title="新型防护技术"></a>新型防护技术</h2><p>PAC</p><p>PXN</p><p>CET</p><p>CFI</p><p>SMEP</p><p>SMAP</p><p>MTE</p><h2 id="作者声明"><a href="#作者声明" class="headerlink" title="作者声明"></a><strong>作者声明</strong></h2><pre><code>本文版权归作者(rohex)所有，旨在技术交流使用。未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则相关责任自行承担。</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> 漏洞 </tag>
            
            <tag> ctf </tag>
            
            <tag> writeup </tag>
            
            <tag> exploits </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ELF符号延迟绑定（动态符号的加载）</title>
      <link href="/2020/01/03/elf-symbol-delay-bind/"/>
      <url>/2020/01/03/elf-symbol-delay-bind/</url>
      
        <content type="html"><![CDATA[<h2 id="过程总结"><a href="#过程总结" class="headerlink" title="过程总结"></a>过程总结</h2><p><strong>首次调用会跳到动态符号的.plt表项的首条指令；该指令会跳转到该符号的.got表项地址，初始时该处存放的是.plt表项的第二条指令；.plt第二条指令会压入该符号的表项号，然后跳入.plt首地址；.plt首地址将got表中的第二项压入栈中（即本模块对应的ID），然后跳转到got表项的第三项执行（ _dl_runtime_resolve函数）； _dl_runtime_resolve函数执行完后，对应的.got表项里就有符号的真实地址；再次调用就可以通过.plt表项的首条指令直接跳到符号真实地址（.got表中解析后的结果）。</strong></p><h2 id="调试"><a href="#调试" class="headerlink" title="调试"></a>调试</h2><ol><li><p>首次调用libc.so的函数，会跳到对应的plt表项的首条指令<br><img src="elf_symbol_delay_bind1.png" alt=""></p></li><li><p>plt首条指令是跳转到.got表里对应的表项<br><img src="elf_symbol_delay_bind2.png" alt=""></p></li><li>got表中有6项，第四项为read<br><img src="elf_symbol_delay_bind3.png" alt=""></li><li>查看此时 read表项值，其对应着read plt表项中的第二条指令<br><img src="elf_symbol_delay_bind4.png" alt=""><ul><li>got表中第一项对应代码的_DYNAMIC节，这个节里保存着动态链接器所需要的信息：比如依赖于哪些共享库、动态符号表位置、初始化代码位置等。<br><img src="elf_symbol_delay_bind5.png" alt=""></li><li>第二项对应本模块的ID</li><li>第三项对应，动态链接库的 _dl_runtime_resolve函数<br><img src="elf_symbol_delay_bind6.png" alt="">       </li></ul></li><li>再回头看看plt表项中的第二条指令，它会压入 read函数对应的got表项序号（去掉前3项），然后跳转到plt表的首段0x080482F0<br><img src="elf_symbol_delay_bind7.png" alt="">   </li><li>plt首地址的代码 将got表中的第二项压入栈中（即本模块对应的ID），然后跳转到got表项的第三项执行（ _dl_runtime_resolve函数）<br><img src="elf_symbol_delay_bind8.png" alt="">  </li><li><p>经过 _dl_runtime_resolve函数解析完，got表中就添入了read函数真实地址<br><img src="elf_symbol_delay_bind9.png" alt="">  </p></li><li><p>查看该地址处符号，为read<br><img src="elf_symbol_delay_bind10.png" alt="">  </p></li><li>反汇编该处指令<br><img src="elf_symbol_delay_bind11.png" alt=""></li></ol><h2 id="作者声明"><a href="#作者声明" class="headerlink" title="作者声明"></a><strong>作者声明</strong></h2><pre><code>本文版权归作者(rohex)所有，旨在技术交流使用。未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则相关责任自行承担。</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> ELF </tag>
            
            <tag> 延迟绑定 </tag>
            
            <tag> 符号加载 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Glibc堆内存管理知识梳理</title>
      <link href="/2020/01/03/ptmalloc2/"/>
      <url>/2020/01/03/ptmalloc2/</url>
      
        <content type="html"><![CDATA[<h2 id="前言："><a href="#前言：" class="headerlink" title="前言："></a>前言：</h2><p>在读了<a href="https://paper.seebug.org/papers/Archive/refs/heap/glibc%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86ptmalloc%E6%BA%90%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90.pdf" target="_blank" rel="noopener">Ptmalloc2源代码分析</a>和阿里牛人文章<a href="https://yq.aliyun.com/articles/53850?spm=a2c4e.11153940.blogcont6274.13.57fc1dc2Pm9J3W" target="_blank" rel="noopener">Linux堆内存管理深入分析</a>后，本文以一种 <font color="#FF0000">有序的知识点摘要</font>形式重新梳理下堆内存管理知识，希望可以将堆内存管理知识点进行概括、总结、串联，本文适合对堆内存管理有一定零星了解，通过本文将知识点串起来。</p><h2 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h2><ol><li><p>当前针对各大平台主要有如下几种堆内存管理机制：</p><ul><li>dlmalloc – General purpose allocator</li><li><font color="#FF0000" face = "微软雅黑" size=3>ptmalloc2 – glibc </font></li><li>jemalloc – FreeBSD, Firefox, Android5.0-</li><li>tcmalloc – Google</li><li>libumem – Solaris <p align="left">堆内存管理的核心目的是能够高效地分配和回收内存块(chunk)。</p></li></ul></li><li><p>首次malloc申请内存（小于128k，大内存由mmap系统函数直接分配），查看进程maps文件可看出分配了132kb的堆内存（使用brk申请），这132KB的堆空间叫做arena，主线程分配的叫做main arena。</p></li><li><p><strong>不是每次malloc申请内存都会用系统调用来映射内存，而是初次申请便映射一大块内存交由arena管理，由arena进行内存分配和回收。</strong>在主线程调用free之后：从内存布局可以看出程序的堆空间并没有被释放掉，而是由glibc的ptmalloc2使用arena结构进行管理。  </p></li><li><p>主线程和子线程有自己独立的arena，新线程会通过nmap分配一个新的arena，但arena数量有限制：<br>  &emsp;<em>For 32 bit systems:   Number of arena = 2 </em> number of cores + 1.<br>  &emsp;For 64 bit systems:   Number of arena = 8 <em> number of cores + 1.</em><br>当glibc能维护的arena个数已经达到上限，无法再为新线程分配新的arena，那么复用已存在的arena（遍历可用arena，lock成功后返回给线程，暂时无可用的会阻塞malloc操作直到可用）</p></li><li><p>main arena被分配的内存空间是连续的，当管理的空闲内存不够分配时，通过系统调用sbrk扩展heap，<strong>堆空间是向上增长的</strong>，sbrk只需将arena管理的最高地址增加即可；而thread arena管理的内存区域可能不连续，初始化时或每次空间不够时，都是系统使用mmap分配一块内存，为了让这些分离的堆块方便管理，ptmalloc2在使用_heap_info数据结构将其联系起来。</p></li><li><p>在ptmalloc2中，chunk是堆内存管理单元，有4种类型，除了按是否空闲分为allocated chunk和malloc_chunk，还有两个特殊类型的chunk：top chunk和Last remainder chunk，其中：</p><ul><li>Top Chunk<br>当一个chunk处于一个arena的最顶部(即最高内存地址处)的时候，就称之为top chunk。在系统当前的所有空闲chunk都无法满足用户请求的内存大小的时候，将此chunk当做一个应急消防员，分配给用户使用。如果top chunk的大小比用户请求的大小要大的话，就将该top chunk分作两部分：1）用户请求的chunk；2）剩余的部分成为新的top chunk。否则，就需要扩展heap或分配新的heap了，在main arena中通过sbrk扩展heap，而在thread arena中通过mmap分配新的heap。</li><li>Last Remainder Chunk<br>Last remainder是另外一种特殊的chunk，当需要分配一个small chunk，但找不到合适的chunk，如果last remainder chunk的大小大于所需的small chunk大小，last remainder chunk被分裂成两个chunk，其中一个chunk返回给用户，另一个chunk变成新的last remainder chuk。  </li></ul></li><li><p>到此为止，已经了解了arena、heaps、chunk的概念，现在可以通过两张图理解清楚它们之间的联系(<font size=2><strong>图引自阿里云栖社区文章<a href="https://yq.aliyun.com/articles/53850?spm=a2c4e.11153940.blogcont6274.13.57fc1dc2Pm9J3W" target="_blank" rel="noopener">《Linux堆内存管理深入分析》</a></strong></font>)：</p><ul><li><p><strong>main_arena</strong><br><img src="ptmalloc2_main_arena.png" alt="&quot;main arena&quot;"></p><center> <font size=2 face="黑体">图1：main arena内存布局</font></center>  <ul><li>左上角是arana数据结构，右侧是被arena管理的一片连续的内存块；  </li><li>可以看出内存块被割裂成3种chunk：top chunk，空闲chunk(即malloc_chunk，为malloc机制主要管理的chunk)，和以分配chunk(allocted chunk)，<strong>Last remainder属于特殊的空闲chunk，是分配samall chunk时产生的剩余，其空间中的位置会随时变化</strong>；</li><li>top chunk在arena管理内存空间的最高地址，在内存不够时，可以直接向上扩展。因此，main arena中不存在heaps；</li><li>arena的主要业务就是组织管理空闲chunk，回收已分配的chunk，并在合适的时机合并被隔离成碎片的空闲chunk;     </li></ul></li><li><p><strong>thread arena</strong><br><img src="ptmalloc2_thread_arena.png" alt="&quot;thread arena&quot;"><br><center> <font size=2 face="黑体">图2：thread arena内存布局</font></center></p><ul><li>这是一个包含2个heap的thread arena，heap的起始地址处是heap_info数据结构，用来连接多个heap；</li><li>线程arena数据结构在第一个heap中，增加新的heap会改变arena数据结构中top chunk的指向（新分配的heap地址更高）；</li><li>另外，main arena数据结构是存放在libc.so的可写数据段中。   </li></ul></li></ul></li></ol><h2 id="数据结构：chunk、bin及arena"><a href="#数据结构：chunk、bin及arena" class="headerlink" title="数据结构：chunk、bin及arena"></a>数据结构：chunk、bin及arena</h2><ol><li><p>堆内存管理单元chunk<strong>设计为方便分配和回收的数据结构</strong>，ptmalloc2将整个堆内存空间分成了连续的、大小不一的chunk（大小必须为8的倍数），下图为chunk基础数据结构：<br><img src="ptmalloc_freechunk.png" alt="&quot;chunk format&quot;">   </p><center><font size=2 face="黑体">图3：chunk的数据结构</font></center>  <ul><li><strong>pre chunk size</strong><br>前一个chunk的大小。只有在前一个chunk是空闲时才有用，在ptmalloc2做内存管理时索引前一个空闲chunk的地址（前一个chunk是空闲，<font color="#FF0000">如果当前chunk被释放时，会需要前一个空闲chunk的地址去完成两个连续空闲chunk的合并</font>）；前一个chunk被分配时，可以做前一个chunk的用户空间。 </li><li><strong>chunk size</strong><br>当前chunk大小，包括给malloc调用者使用的空间和做内存管理的消耗空间，大小是8字节对齐，所以后3位可以作其它用。 </li><li><strong>N/M/P标志位</strong><br>N (NON_MAIN_ARENA)：表示当前chunk是否是thread arena。<br>M (IS_MMAPPED)：表示当前chunk是否是通过mmap系统调用产生的。<br>P (PREV_INUSE): 表示前一个chunk是否为allocated。</li><li><p><strong>fd和bk</strong><br>chunk空闲时会有，分别表示chunk双向链表的前向指针和后项指针。   </p><p><strong>空闲chunk的数据结构定义：</strong><br>struct malloc_chunk {<br>INTERNAL_SIZE_T      prev_size;  /<em> Size of previous chunk (if free).  </em>/<br>INTERNAL_SIZE_T      size;       /<em> Size in bytes, including overhead. </em>/<br>// 这两个指针只在free chunk中存在<br> struct malloc_chunk<em> fd;<br> struct malloc_chunk</em> bk;<br>// 这两个指针只在large chunk中存在<br> struct malloc_chunk<em> fd_nextsize;<br>struct malloc_chunk</em> bk_nextsize;<br>};<br> <strong>通过大小去检索和操作前后chunk称为隐式链表技术。</strong></p></li></ul></li><li>组织空闲chunk的双向链表bin<br><font color="#FF0000">ptmalloc2最核心的目的</font>是管理空闲的chunk，已分配的chunk不做管理，主要业务是<font color="#FF0000">为malloc调用者提供最合适的空闲chunk，回收free后的chunk</font>，因此设计了<strong>4种链表数组</strong>（数组元素存放chunk类型的链表指针）来满足用户对chunk不同大小的请求，这个链表数组被称为bins，每个数组元素为一个bin，每种不同的bins管理不同类型chunk，分别为：<ul><li>Fast bins：用如其名，是最快的分配方式，数量为10个bin，chunk size分别为16到80字节；</li><li>Unsorted bin： 暂不作分类的chunk都放在该bin下，数量为1个；</li><li>Small bins: 小于512个字节时，分配该类bin下chunk，62个；</li><li>Large bins: 大于512字节时。分配该类bin下的chunk，63个。<br>&lt;/br&gt;      </li></ul></li><li><p>管理空闲chunk的arena结构<br> struct malloc_state<br> {<br>   mutex_t mutex;  /<em> Serialize access.  </em>/</p><p>   int flags;   /<em> Flags (formerly in max_fast).  </em>/</p><p>   <font color="#FF0000">mfastbinptr fastbinsY[NFASTBINS];</font>  /<em> Fastbins </em>/</p><p>   <font color="#FF0000">mchunkptr top;</font> /<em> Base of the topmost chunk — not otherwise kept in a bin </em>/</p><p>   <font color="#FF0000">mchunkptr last_remainder;</font> /<em> The remainder from the most recent split of a small request </em>/</p><p>   <font color="#FF0000">mchunkptr bins[NBINS * 2 - 2];</font>  /<em> Normal bins packed as described above </em>/</p><p>   unsigned int binmap[BINMAPSIZE];  /<em> Bitmap of bins </em>/</p><p>   struct malloc_state <em>next;  /</em> Linked list */</p><p>   struct malloc_state <em>next_free;   /</em> Linked list for free arenas.  */</p><p>   INTERNAL_SIZE_T system_mem;   /<em> Memory allocated from the system in this arena.  </em>/</p><p>   INTERNAL_SIZE_T max_system_mem;</p><p> };  </p><ul><li>arena管理内存的数据结构为malloc state；</li><li>fastbinsY即为上文提到的fastbins，里面存放的是可用来快速分配的小chunk；</li><li>top指向top chunk，top chunk是一种特殊的空闲chunk，也用来分配内存；</li><li>last_remainder和top chunk一样；</li><li>bins保存了usorted bin，samall bins, large bins，其中    bins[0]为unsorted bin，<br>bin[1:63]为small bin,bins[63:127]为large bin。</li></ul></li></ol><h2 id="堆块的分配、释放与合并"><a href="#堆块的分配、释放与合并" class="headerlink" title="堆块的分配、释放与合并"></a>堆块的分配、释放与合并</h2><h3 id="堆块的分配"><a href="#堆块的分配" class="headerlink" title="堆块的分配"></a>堆块的分配</h3><ol><li>首先将用户请求大小转化为实际需要分配的堆块大小，加上chunk结构中presize和size大小；</li><li>如果chunk_size &lt;= max_fast（默认64B），则尝试在fastbins中取所需大小的chunk返回，分配结束；（优先分配fastbins）</li><li>如果2不满足，如果chunk_size &lt;= 521B（smallbins范围），则尝试在smallbins中取所需大小的chunk返回，分配结束(是否会切分较大的smallbin，将剩余部分放到unsorted bin，last remainder chunk指向剩余的chunk。)；</li><li>如果fastbins和smallbins都不满足，则首先合并fastbins，将合并后的chunk链入unsorted bin；然后遍历unsorted bin，如果满足：a.只有一个chunk;b.该chunk在上次分配被使用过；c.chunk大小属于small范围;d.chunk大于所需分配大小，则切分该chunk，分配结束，否则遍历unsorted bin将chunk放到对应的samll和large bins；<br><img src="ptmalloc2_chunk_judge.png" alt="ptmalloc2_chunk_judge">   </li><li>到了这一步，fastbins、smallbins、unsortedbin都无合适的chunk分配，其中fastbins、unsortedbi已被清空。这时需从large bins中分配，从large bins中按照“smallest-first，best-fit”原则，找一个合适的 chunk，从中划分一块所需大小的chunk，并将剩下的部分链接回到bins中；</li><li>如果搜索fast bins和bins都没有找到合适的chunk，那么就需要操作top chunk来进行分配了。判断top chunk大小是否满足所需chunk的大小，如果是，则从top chunk中分出一块来。否则转到下一步。</li><li>到了这一步，说明top chunk也不能满足分配要求，所以，于是就有了两个选择: 如果是主分配区，调用sbrk()，增加top chunk大小；如果是非主分配区，调用mmap来分配一个新的sub-heap，增加top chunk大小；或者使用mmap()来直接分配。在这里，需要依靠chunk的大小来决定到底使用哪种方法。判断所需分配的chunk大小是否大于等于 mmap分配阈值，如果是的话，则转下一步，调用mmap分配，否则跳到第12步，增加top chunk 的大小。 </li></ol><h3 id="堆块的释放"><a href="#堆块的释放" class="headerlink" title="堆块的释放"></a>堆块的释放</h3><ol><li>free() 函数接受一个指向分配区域的指针作为参数，释放该指针所指向的chunk。</li><li>判断传入的指针是否为0，如果为0，则什么都不做，直接return。否则转下一步。</li><li>判断所需释放的chunk是否为mmaped chunk，如果是，则调用munmap()释放mmaped chunk，解除内存空间映射，该该空间不再有效。如果开启了mmap分配阈值的动态调整机制，并且当前回收的chunk大小大于mmap分配阈值，将mmap分配阈值设置为该chunk的大小，将mmap收缩阈值设定为mmap分配阈值的2倍，释放完成，否则跳到下一步。</li><li>判断chunk的大小和所处的位置，若chunk_size &lt;= max_fast，并且chunk并不位于heap的顶部，也就是说并不与top chunk相邻，则将chunk放到fast bins中，chunk放入到fast bins中时，并不修改该chunk使用状态位P。也不与相邻的chunk进行合并。只是放进去，如此而已。这一步做完之后释放便结束了，程序从free()函数中返回。（因为与top chunk相邻的小chunk也和 top chunk进行合并，所以这里不仅需要判断大小，还需要判断相邻情况）</li><li>判断前一个chunk是否处在使用中，如果前一个块也是空闲块，则合并。</li><li>判断当前释放chunk的下一个块是否为top chunk（相较于当前chunk的高地址方向）（top chunk从低地址开始划分，向高地址扩展），如果是，与top chunk合并，并更新top chunk的大小等信息。</li><li>如下一个不是top chunk，判断下一个chunk是否处在使用中，如果下一个chunk也是空闲的，则合并，并将合并后的chunk放到unsorted bin中；</li><li>判断合并后的chunk 的大小是否大于FASTBIN_CONSOLIDATION_THRESHOLD（默认64KB），如果是的话，则会触发进行fast bins的合并操作，fast bins中的chunk将被遍历，并与相邻的空闲chunk进行合并，合并后的chunk会被放到unsorted bin中。fast bins将变为空，操作完成之后转下一步。</li><li>判断top chunk的大小是否大于mmap收缩阈值（默认为128KB），如果是的话，对于主分配区，则会试图归还top chunk中的一部分给操作系统。但是最先分配的128KB空间是不会归还的，ptmalloc 会一直管理这部分内存，用于响应用户的分配请求；如果为非主分配区，会进行sub-heap收缩，将top chunk的一部分返回给操作系统，如果top chunk为整个sub-heap，会把整个sub-heap还回给操作系统。  </li></ol><h3 id="堆块的合并"><a href="#堆块的合并" class="headerlink" title="堆块的合并"></a>堆块的合并</h3><ol><li>堆块释放时，会判断当前 chunk 的相邻 chunk 是否为空闲状态，若是则会进行堆合并。合并时会将空闲 chunk 从 bin 中 unlink，并将合并后的 chunk 添加到 unsorted bin 中。堆合并分为向前合并和向后合并。  </li><li>向后合并：  <ul><li>判断当前chunk的P(PREV_INUSE)标志位是否为0（0代表前一个chunk状态是free）；</li><li>前一个chunk若为空闲，则将当前chunk指向前一个，更新chunk size，释放前一个chunk；</li><li>更新合并后的chunk到bin中。</li></ul></li><li>向前合并：<ul><li>通过next-&gt;next-&gt;prev_inuse判断next chunk是否为空闲；</li><li>若为空闲，则更新合并后chunk大小，unlink next chunk；</li><li>更新合并后的chunk到bin中。</li></ul></li><li><p>unlink：  </p><ul><li>dlmlloc或ptmalloc2中定义unlink如下：<br>/<em> Take a chunk off a bin list </em>/<br>#define unlink(P, BK, FD) {<br>FD = P-&gt;fd;<br>BK = P-&gt;bk;<br>FD-&gt;bk = BK;<br>BK-&gt;fd = FD;<br>}  </li><li>Glibc 增加了安全检查：<br>/<em> Take a chunk off a bin list </em>/<br>#define unlink(P, BK, FD) {<br>FD = P-&gt;fd;<br>BK = P-&gt;bk;<br>if (__builtin_expect (FD-&gt;bk != P || BK-&gt;fd != P, 0))<br>malloc_printerr (check_action, “corrupted double-linked list”, P);<br>else {<br>FD-&gt;bk = BK;<br>BK-&gt;fd = FD;        …<br>}<br>}  </li></ul><p><strong>bin链中该chunk的前chunk的bk和后chunk的fd都应该指向P，最后unlink被改写的也只能是存放P指针的前chunk-&gt;bk与后chunk-&gt;fd。</strong> </p></li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://yq.aliyun.com/articles/53850?spm=a2c4e.11153940.blogcont6274.13.57fc1dc2Pm9J3W" target="_blank" rel="noopener">Linux堆内存管理深入分析 (上)</a><br><a href="https://yq.aliyun.com/articles/53852?spm=a2c4e.11153940.0.0.6fe7644bYxaIT1" target="_blank" rel="noopener">Linux堆内存管理深入分析 (下)</a><br><a href="https://paper.seebug.org/papers/Archive/refs/heap/glibc%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86ptmalloc%E6%BA%90%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90.pdf" target="_blank" rel="noopener">Glibc内存管理 Ptmalloc2源代码分析 庄明强</a>  </p><h2 id="作者声明"><a href="#作者声明" class="headerlink" title="作者声明"></a><strong>作者声明</strong></h2><pre><code>本文版权归作者(rohex)所有，旨在技术交流使用。未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则相关责任自行承担。</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Glibc </tag>
            
            <tag> ptmalloc2 </tag>
            
            <tag> unlink </tag>
            
            <tag> 堆溢出 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>android bin kits</title>
      <link href="/2020/01/02/android-bin-kits/"/>
      <url>/2020/01/02/android-bin-kits/</url>
      
        <content type="html"><![CDATA[<h2 id="What？"><a href="#What？" class="headerlink" title="What？"></a>What？</h2><p>android_bin kits是一个工具集，仅围绕一个目的进行：<strong>分析Android系统中的可执行文件（dex、odex、oat、vdex）中有什么？</strong>  </p><h2 id="Why？"><a href="#Why？" class="headerlink" title="Why？"></a>Why？</h2><p>Android native层代码经过编译后会有3种形式：静态库、动态库、elf可执行文件，而静态库最终会链接到动态库或可执行文件中去，最后android系统中native代码只会以动态库和elf可执行文件的形式存在，通过源码工程文件中的makefile、android.mk、android.bp等编译配置文件，我们可以精确的知道某个源码文件或某个函数最后会以什么样形式存在系统哪个文件中； <br/><br><strong>然而，你能通过java源码工程文件知道java代码最后会存在于系统中的哪个可执行文件中吗？</strong>我们只能看到java类代码会被封装成哪个jar包，jar包会转成dex文件，然后android系统还会对dex文件进行优化，生成odex、oat、vdex、cdex、art之类文件。这一切都是android打包程序和dex优化程序做的手脚，那么想找出java源码与系统可执行文件的关系有两条路：研究android打包和优化原理，或逆向可执行文件获得想要的信息？  <br/><br>我选择使用后者方式去<strong>实现java源码与可执行文件的关联。</strong>因为android系统每个版本优化dex文件的机制和文件格式都会有所变化，这个打包和优化的过程也时刻在变。虽然逆向可执行文件也要面临同样的繁琐，但好在Android的各个阶段都有一些好的工具，我只需要利用他们实现我的目的。</p><h2 id="How"><a href="#How" class="headerlink" title="How ?"></a>How ?</h2><ul><li><strong><em>adbtool.py</em></strong> 主要涉及一些用来和android系统交互的接口，用来做系统信息获取和文件拉取；</li><li><strong><em>android_bin.py</em></strong> 是对dex、odex、oat等文件进行分析，得到class、method、feilds、strings等信息，该脚本依赖开源工具<a href="http://newandroidbook.com/tools/dextra.html" target="_blank" rel="noopener">dextra</a>；</li><li><strong><em>vdex2dex.py</em></strong> 封装了android8/9 vdex抽取dex的工具，其所得dex文件可以使用android_bin进一步分析，该脚本依赖开源工具<a href="https://github.com/anestisb/vdexExtractor" target="_blank" rel="noopener">vdexExtractor</a>；</li><li><strong><em>filesystem_analyze.py</em></strong> 对整个安卓系统的可执行文件进行分析，也可以查询某个源码类被包含在哪个可执行文件中,该脚本依赖以上3个脚本。</li></ul><h2 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h2><ul><li><strong>1.拉取android系统所有可执行文件到文件夹android-8.0中</strong><br/><br><strong><em>filesystem_analyze.py -pull -o android-8.0</em></strong><br><em>/data/dalvik-cache/x86/system@app@Cube…lled. 2.7 MB/s (20904 bytes in 0.007s)<br>/system/app/Amaze/oat/x86/Amaze.vdex: …ed. 8.4 MB/s (6111971 bytes in 0.692s)<br>/system/app/BasicDreams/oat/x86/BasicD…lled. 1.6 MB/s (15795 bytes in 0.009s)<br>Command ‘adb pull /system/app/DeskClock/oat/x86/DeskClock.vdex android-8.0’ time<br>d out after 2 seconds<br>pull /system/app/DeskClock/oat/x86/DeskClock.vdex faild, try again.</em></li></ul><ul><li><strong>2.对可执行文件系统进行分析，输出可执行文件包含java类信息到     android8-class.json文件中</strong><br/><br><strong><em>filesystem_analyze.py -class -i android-8.0 -o android8-class.json</em></strong>   <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&quot;system@framework@boot-framework.vdex&quot;: &#123;</span><br><span class="line"></span><br><span class="line">    &quot;AbstractAccountAuthenticator.java&quot;: &quot;81&quot;,  </span><br><span class="line">    &quot;AbstractThreadedSyncAdapter.java&quot;: &quot;1483&quot;,  </span><br><span class="line">    &quot;AccessibilityButtonController.java&quot;: &quot;31&quot;,  </span><br><span class="line">    &quot;AccessibilityService.java&quot;: &quot;48&quot;,  </span><br><span class="line">    &quot;AccessibilityServiceInfo.java&quot;: &quot;57&quot;,    </span><br><span class="line">    &quot;AccountAndUser.java&quot;: &quot;84&quot;,  </span><br><span class="line">    &quot;AccountManager.java&quot;: &quot;128&quot;,  </span><br><span class="line">    &quot;AccountManagerCallback.java&quot;: &quot;125&quot;,   </span><br><span class="line">    &quot;AccountManagerFuture.java&quot;: &quot;89&quot;,   </span><br><span class="line">    &quot;AccountManagerInternal.java&quot;: &quot;130&quot;,   </span><br><span class="line">    </span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>3.查询某个类文件包含在哪些可执行文件中</strong><br/><br><strong><em>filesystem_analyze.py -query -i android8-class.json —class-name ActivityManagerInternal.java</em></strong><br><em>precise match as follow:</em><br><em>system@framework@boot-framework.vdex include ActivityManagerInternal.java</em><br><em>boot-framework.vdex include ActivityManagerInternal.java</em>   </p></li><li><p><strong>更多</strong><br>执行python3 xxx.py，会打印readme。</p></li></ul><h2 id="作者声明"><a href="#作者声明" class="headerlink" title="作者声明"></a><strong>作者声明</strong></h2><pre><code>本文版权归作者(rohex)所有，旨在技术交流使用。未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则相关责任自行承担。</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> 工具 </tag>
            
            <tag> 逆向 </tag>
            
            <tag> Android </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>binsign（关于二进制代码定位和特征搜索的项目）</title>
      <link href="/2020/01/02/binsign/"/>
      <url>/2020/01/02/binsign/</url>
      
        <content type="html"><![CDATA[<h2 id="它是什么？"><a href="#它是什么？" class="headerlink" title="它是什么？"></a>它是什么？</h2><p><strong>binsign</strong>是一个能够分析二进制代码特征的开源项目，它可以在不同平台中通过<strong>强特征</strong>定位到特定的二进制函数中，并可以搜索感兴趣的二进制特性。这些特征包括但不限于常量、引用、函数原型、局部变量、特殊指令等。更形象地说，我想做一个可以分析和提取二进制文件DNA的东西，并且可以在这个二进制文件的历史变化中掌握它的进化信息和二进制特点。  </p><h2 id="技术相关的项目？"><a href="#技术相关的项目？" class="headerlink" title="技术相关的项目？"></a>技术相关的项目？</h2><p>一个被编译成机器码的函数，它有什么特征可以唯一表征这个函数呢？让我们来看看当前是否有相关研究或项目可以提供下思路。</p><h3 id="BinDiff"><a href="#BinDiff" class="headerlink" title="BinDiff"></a>BinDiff</h3><p>BinDiff是第一个要介绍的工具,它是用来做二进制代码相似性分析。这个工具在二进制补丁比对领域上享有盛名，最早由恶意软件分析工具厂商zynamics开发并作为商业工具发布，后由google收购并开源。BinDiff所使用的算法不是依赖于函数基本块的实际内容，而是使用基于图的方法表征可执行文件函数：调用图CG（call graph）和流程图CFG（control-flow graph），CG表示方法（函数）在整个程序中的调用关系，图中的节点是方法，边表示调用关系；CFG表示一个方法内的程序执行流，图中的节点是语句（指令），边表示执行流。</p><h3 id="KARTA"><a href="#KARTA" class="headerlink" title="KARTA"></a>KARTA</h3><p>KARTA是以色列安全公司CheckPoint开源的一个IDA插件，用于识别和匹配给定二进制文件中的开源库。它的大致思路是先从开源库中提取二进制代码特征，然后去匹配目标二进制文件。这个地方我们重点关注它所提取的二进制代码特征，它介绍中提到的代码特征有【跳转表，代码段中的字符串和数字常量（主要存在ARM中），全局字符串，全局指针】。另外有2个点也值得关注下1）时间代价的瓶颈主要是IDA，分析TeamViewer整个过程大约花费了2个小时（相当大的程序，其中包含143,000多个函数）；2）为了弥补IDA对函数快识别的不准确，应用了Random-Forest（随机森林）分类器来识别函数的开头和结尾，结果得到了很大的提高。</p><h3 id="Binmap"><a href="#Binmap" class="headerlink" title="Binmap"></a>Binmap</h3><p>Binmap是Quarkslab开源的一个系统扫描程序，它通过遍历一个系统或系统镜像的所有文件，查找程序、库并收集各种信息，例如依赖项、符号等，为系统建立一个散列和信息数据库。目标之一是提供包含多个系统数据库的一种仓库，并更新数据库以跟踪二进制系统的发展。Binmap是一个很宏伟的项目，我的理解是它想做一个二进制版的github commits管理。LIEF是为Binmap提供二进制分析的基础工具，也是Quarkslab另一个开源项目，它就是提供各种系统架构下的elf文件的解析和修改，也可以用来hook。但是可解析数据和readelf能力差不多，只是些elf信息读取和展示，没有做进一步的高级分析。不过有一点非常值得赞的是，它不但支持x86/x64、ARM这类纯二进制代码，它也支持Android系统里java编译出的DEX、ODEX、VDEX、OAT二进制文件的解析。而且，项目首页对Android可执行文件的描述非常清晰（在此吐槽下Android系统的java类可执行文件真是个变化无常的渣男,不过LIEF懂它）。</p><h3 id="Abidiff"><a href="#Abidiff" class="headerlink" title="Abidiff"></a>Abidiff</h3><p>Abidiff是GNU开源项目libabigail的一个附带工具，它比较两个ELF共享库的应用程序二进制接口（ABI，Application Binary Interface），并打印告警信息。 这个工具的主要目标在于检查两个二进制文件是否有影响接口兼容性的变化。它所分析的二进制接口特征都是属于ABI范畴,例如符号接口的增加或删除，或许也会比较接口的参数变化（看着太粗粒度就没在深究），带有DWARF格式的调试信息下更加准确。</p><p><strong>从以上4种涉及二进制接口特征分析的工具来看</strong>：  </p><ol><li>BinDiff提取函数CFG图，然后通过图对比去做二进制代码的相似性分析，特征是CFG，结果是相似与否。其特征和结果对我来说都不够细致和具体，无法借鉴；  </li><li>KARTA的二进制特征看起来很好理解和描述，但是很多二进制函数可能没有类似的特征，而且这种特征也不够唯一。不过它只是想去识别一个开源库，其实不需要提取太多特征，所以特征方面不用追求太多太细。<strong>不过，它提出的有些特征我会考虑提取，作为二进制特性描述</strong> ；  </li><li>Binmap对二进制特征的分析太浅了，仅仅靠readelf的分析能力，粒度也比较粗，它的粒度不是函数，而是二进制文件；  </li><li>Abidiff虽然分析的粒度是二进制函数，但分析的也比较浅，也是readelf的分析级别。  </li></ol><p><strong>我的目的是二进制代码的特征表示和特征搜索，其特征都是可被解读的代码特性。目前，还没有能满足我内心的工具。</strong></p><h2 id="我心目中的样子？"><a href="#我心目中的样子？" class="headerlink" title="我心目中的样子？"></a>我心目中的样子？</h2><p><strong>1.分析一个二进制文件，正确识别出所有函数块；</strong><br><strong>2.抽象函数的强特征和弱特征，其中：</strong><br>1）强特征可以唯一表征该函数，用于快速定位该函数；<br>2）弱特征用于描述函数的其他特性，用于分析函数的变化；<br>3）强特征和弱特征都可由一组特征表示，例如需要几个维度共同确定该二进制函数，称为特征向量；<br><strong>4.特征有以下：</strong><br>1）函数原型，包括参数和返回；<br>2）常量字符串、常量数据、全局变量、静态变量的引用；<br>3）代码引用（coderef_to）、代码调用（函数内部代码流程，调用的函数），一定程度上能代表函数的CG和CFG；<br>4）栈空间分布，局部变量信息；<br><strong><em>特征在分析阶段不区分强弱，最后在整个二进制文件中根据检查单个特征或组合特征在该二进制文件的唯一性，区分强、弱特征。</em></strong></p><h2 id="技术选型？"><a href="#技术选型？" class="headerlink" title="技术选型？"></a>技术选型？</h2><p>我是想站在巨人的肩膀上，用最小的工作量实现最有用的功能。熟悉二进制的人这时候也明白多数的基础分析能力IDA都可以满足，不过经过一番研究后我放弃了它。有这么几个原因：<br>1）它部分功能不能用，例如获取函数参数的python接口，笔者实验过多次返回总是错误的；<br>2）分析太慢了，这点就是KARTA工具苦恼的地方；<br>3）不是开源，Linux版本难以获取，free版本不支持那么多的分析（这也是最重要的，如果不考虑速度和开源性，在windows上实现个插件是最快的方式）；<br>4）最重要的一个原因是，因为工作中遇到的问题，我踏出了从零开始的第一步，那就继续干下去吧。另外说一下Ghidra（NSA 2019年初开源的一个类似于IDA的反编译工具），我也尝试用了下。不过它太慢了，比ida慢估计有10倍了；而且文档特别差，我先弃了它。<br>最终我用了readelf和objdump两个工具作为基础，我没有完全从零开始，毕竟也不需要。readelf满足了我对elf文件解析的需求，objdump帮助我反汇编了各个架构的代码；这样我只需要去扫描汇编代码去实现更高级的分析功能，这样我也能更接近elf文件和汇编的原理，这种探索也会给人带来乐趣。也许依赖shell命令实现有些low了，不过至少还有GNU binutils（readelf和objdump属于其项目工具）和elfutils库可以去替代。</p><h2 id="目前实现"><a href="#目前实现" class="headerlink" title="目前实现"></a>目前实现</h2><p>X86、ARM32常量引用分析。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.zynamics.com/bindiff.html" target="_blank" rel="noopener">bindiff项目</a><br><a href="https://github.com/CheckPointSW/Karta" target="_blank" rel="noopener">KARTA项目开源地址</a><br><a href="https://blog.quarkslab.com/binmap-a-system-scanner.html" target="_blank" rel="noopener">Binmap项目</a><br><a href="https://lief.quarkslab.com/" target="_blank" rel="noopener">LIEF项目</a><br><a href="https://sourceware.org/libabigail/manual/abidiff.html" target="_blank" rel="noopener">libabigail:Abidiff使用说明</a> </p><h2 id="作者声明"><a href="#作者声明" class="headerlink" title="作者声明"></a><strong>作者声明</strong></h2><pre><code>本文版权归作者(rohex)所有，旨在技术交流使用。未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则相关责任自行承担。</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> 逆向 </tag>
            
            <tag> 二进制 </tag>
            
            <tag> 函数摘要 </tag>
            
            <tag> 相似性比对 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于二进制分析技术的开源漏洞检测方法概述</title>
      <link href="/2020/01/02/bin-vul-check/"/>
      <url>/2020/01/02/bin-vul-check/</url>
      
        <content type="html"><![CDATA[<p><img src="bin_vul_check.png" alt="基于二进制分析技术的开源漏洞检测方法分类"></p><h2 id="1-开源很重要，漏洞更加值得关注"><a href="#1-开源很重要，漏洞更加值得关注" class="headerlink" title="1.开源很重要，漏洞更加值得关注"></a>1.开源很重要，漏洞更加值得关注</h2><p>开源代码在互联网技术中扮演的角色愈发重要，例如Linux、Android、GNU开源项目，它们构成了互联网及物联网大厦的地基，现在很难说哪个厂商开发的设备或app不依赖于任何开源代码。对开源漏洞进行检测还是很有必要的！目前黑客入侵的最高效简单的方式就是通过已知开源代码的漏洞进行入侵，也就是说如果厂商的代码存在高危的开源漏洞，那在黑客眼中就如同裸奔。</p><h2 id="2-为什么是二进制分析技术"><a href="#2-为什么是二进制分析技术" class="headerlink" title="2.为什么是二进制分析技术"></a>2.为什么是二进制分析技术</h2><p>如果通过源码检测开源漏洞，那就是个简单的补丁文件文本匹配问题。这个问题我也想过，但二进制分析依然有存在的需要：通过源码检测属于白盒审计过程，它存在于代码产品研发阶段。可以说，如果开源代码引入和应急响应做得好，二进制分析是无可作为的，但是根据SDL（安全开发流程）原则，安全应该存在于产品全生命周期中，安全大任仅依靠源码审计阶段是危险的。二进制分析是一个黑盒技术，它通过搜寻公开信息对代码产品的开放形态进行分析，这更符合黑客渗透过程，黑盒方式的漏洞扫描作为SDL对于开源漏洞检测的最后一个环节是必要存在的。而且，目前有能力全流程落入安全管理的厂商还是少的，大多数厂商的产品功能依据已有代码或开源代码二次开发，开源漏洞是广泛存在的，这个问题可以参考<a href="https://keenlab.tencent.com/zh/whitepapers/%E8%85%BE%E8%AE%AF%E5%AE%89%E5%85%A8%E7%A7%91%E6%81%A9%E5%AE%9E%E9%AA%8C%E5%AE%A42018%E5%B9%B4IoT%E5%AE%89%E5%85%A8%E7%99%BD%E7%9A%AE%E4%B9%A6.pdf" target="_blank" rel="noopener">科恩实验室的IOT报告</a>。因此，从黑盒角度出发，运用二进制分析技术去检测开源漏洞是必要的。</p><h2 id="3-通过二进制分析技术检测开源漏洞"><a href="#3-通过二进制分析技术检测开源漏洞" class="headerlink" title="3.通过二进制分析技术检测开源漏洞"></a>3.通过二进制分析技术检测开源漏洞</h2><p>依据上图，二进制分析可以分为静态分析和动态分析，静态、动态的区别就是是否执行指令（实际执行、虚拟执行和模拟执行都属于动态分析）。</p><h3 id="3-1-静态分析"><a href="#3-1-静态分析" class="headerlink" title="3.1 静态分析"></a>3.1 静态分析</h3><ol><li>静态特征检测中，版本检测是最简单的漏洞检测方式，开源代码一般具有严格和规则的版本命名方式，而漏洞披露时一般也会带有影响版本信息。那么将二者联系起来，就可以做一个简单的基于版本扫描的漏洞扫描器。不过版本扫描误报率较大，因为如果产品只是使用了开源的部分代码或者已经打了补丁而没有升级版本号，那么检测出来的漏洞可能是产品中不存在的模块或者已经修补的漏洞。<strong>要知道，打个补丁非常简单，升级版本可能会使产品遇到很多兼容性问题，所以有多少研发不想升级版本可想而知。</strong>常量检测和符号检测是一个相对较为准确且简便的漏洞检测方法。有些漏洞补丁或删除的漏洞代码存在一些二进制下依然存在的常量值（例如打印字符串或初始化数组），这个时候就可以使用该方法检测；补丁中有增减的导出符号（导出函数或变量），那么这个也可以用简单的二进制分析工具（例如readelf）检测与分析。这种方法要看补丁是否有该类的特征，而且要<strong>找准唯一常量特征</strong>，具有一定的局限性，不过可以满足部分漏洞的检测。</li><li>执行流分析中，反编译特征分析是指找出补丁在编译后文件中存在的唯一特征，例如漏洞代码附近引用与被引用的差异，这个可以用IDA脚本来检测；也可以将补丁后的函数（或漏洞函数）提取二进制摘要与目标二进制中该漏洞函数的摘要进行比较，摘要可以使用二进制相似性分析工具<strong><a href="https://www.zynamics.com/bindiff.html" target="_blank" rel="noopener">bindiff</a></strong>采用的CF和CFG图，也可以使用IDA插件<strong><a href="https://github.com/joxeankoret/diaphora" target="_blank" rel="noopener">Diaphora</a></strong>，需要进行一定程度的二次开发，或只用它们函数比较的相似性算法，自己动手丰衣足食。</li><li>中间语言分析技术是为了应对漏洞检测特征在不同指令架构（X86、ARM…）下会发生变化的情况。例如执行流分析中的CF和CFG图在相同源码不同架构下可能是不同的，这样如果需要支持检测不同指令架构，就要对应生成相应的检测模型。通过中间语言将不同架构的指令代码用一种语言表示可以一定程度上降低这种麻烦，当然也存在不同架构下翻译的中间语言差异巨大。<strong>栈空间布局差异检测</strong>是针对补丁代码中存在局部变量差异的情况，这种漏洞和相应补丁修补也经常存在。例如，漏洞是由于不同情况下使用函数中某个局部变量会产生栈空间越界读写，补丁是将局部变量类型由普通结构体变为若干个结构体的联合体，这样可以应对不同结构体的传入都不会产生越界读写，但是对于传入较小结构体变量的情况下，该联合体的使用会将之前函数的栈空间增大（联合体的大小是几个结构体中最大值）。</li></ol><h3 id="3-2-动态分析"><a href="#3-2-动态分析" class="headerlink" title="3.2 动态分析"></a>3.2 动态分析</h3><ol><li>漏洞代码触发技术一般称为POC，但是对于漏洞检测，触发可能不需要通过业务层传递到漏洞代码，毕竟业务层分析需要大量的时间去了解业务和层层调试。可以使用dlopen和dlsym直接构造参数调用漏洞代码触发漏洞，检测函数的返回或漏洞影响的内存变化，可以把它称作<strong>局部POC</strong>。c语言具有导出接口或离导出接口不远的代码可以使用该方法，c++类函数的符号经过修饰，而且存在大量需要构造的对象结构，难度较大。</li><li>HOOK技术既可以作为触发漏洞代码方法的辅助，也可以作为主要方式检测，不过需要找到函数符号或者其它可以hook的点。例如，补丁在原漏洞代码中增加了某个函数的调用，就可以hook漏洞调用代码和新增函数，查看补丁是否增加。目前经常使用的hook工具一般的hook点都是函数符号，这里就不多介绍了，用起来还是很方便的。这里重点推广一下<strong><a href="https://software.intel.com/en-us/articles/pin-a-dynamic-binary-instrumentation-tool" target="_blank" rel="noopener">Intel Pin</a></strong>，<strong>强大而深入骨髓的二进制插桩工具</strong>，它可以进行指令级别、基本块级别、函数级别、执行流级别的插桩，而且提供了各个插桩级别中很多用来过滤插桩点的接口，例如只对JMP指令插桩跟踪。执行流级别被称为trace，它的粒度其实也是基本块，不过它不是对整个二进制文件进行插桩，它只会动态的对执行路径中的基本块进行插桩，这大大节约了插桩的时间代价和空间消耗。（通过在插桩点注册一个回调函数就可以实现hook，这就是插桩和hook的联系，所以通过Intel Pin可以实现更多粒度的hook）</li><li>使用模拟执行技术可以<strong>单独执行函数，甚至片段的指令序列</strong>，例如<a href="https://github.com/unicorn-engine/unicorn" target="_blank" rel="noopener">unicorn</a>或<a href="https://github.com/cea-sec/miasm" target="_blank" rel="noopener">miasm</a>都提供了这样的方法，京东的二进制分析工具<a href="https://sec.thief.one/article_content?a_id=e81bf95af26f0ff148ba2d0df5e0b376" target="_blank" rel="noopener">麒麟</a>基于unicorn貌似把该能力进行了更友好的包装。这很实用，因为在目标检测设备上运行动态检测程序经常由于系统权限和环境依赖问题，使得检测方法失效，甚至代码都难以接触。例如嵌入式设备的内核代码，root权限也无法进行插桩检测(代码空间的rwx属性root应该是改不了的)，在真实设备上严格的权限体系，内核空间可不是我们能随意游走的。如果将目标代码镜像拉下来放到模拟器中执行（也可以把内核提出来），可以使用模拟器提供的丰富的hook功能和栈操作功能，让多数函数满足执行环境，例如hook其他函数调用等，例如入参条件，例如数据段访问条件，进而可以触发漏洞代码。污点跟踪技术是检测漏洞触发的一种辅助技术，漏洞的发生多是由于不合预期的操作了某块内存，这时可以通过污点跟踪技术检测漏洞触发的效果。 </li></ol><h2 id="作者声明"><a href="#作者声明" class="headerlink" title="作者声明"></a><strong>作者声明</strong></h2><pre><code>本文版权归作者(rohex)所有，旨在技术交流使用。未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则相关责任自行承担。</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> 漏洞 </tag>
            
            <tag> 二进制 </tag>
            
            <tag> 开源安全 </tag>
            
            <tag> 概述 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>android可执行文件的综述</title>
      <link href="/2020/01/02/android-exec-files/"/>
      <url>/2020/01/02/android-exec-files/</url>
      
        <content type="html"><![CDATA[<h2 id="1-java-dex-odex-oat-vdex的历史演变"><a href="#1-java-dex-odex-oat-vdex的历史演变" class="headerlink" title="1. java/dex/odex/oat/vdex的历史演变"></a>1. java/dex/odex/oat/vdex的历史演变</h2><ul><li>在应用开发时，Android代码的主要部分通常用<strong>Java</strong>编写；APK构建时，java源码首先用javac编译成<strong>Java字节码</strong> ，然后Android通过使用d8编译器将此字节码转换为<strong>DEX文件</strong>（Dalvik字节码）。</li><li>在Android 4.4（KitKat）之前，运行时使用JIT编译将Dalvik字节码转换为目标机器代码，JIT在每次执行应用程序时都会执行，因此代码执行效率很低。从Android 4.4开始，引入新的运行时ART，它在安装过程中执行优化，安装需要更多时间，但转换为本机代码只需执行一次。</li><li>为了优化DEX字节码，原始DEX文件（例如classes.dex）被提取和转换为另一个包含机器代码的文件。这个新文件通常具有<strong>.odex</strong> ，<strong>.oat</strong>扩展名；</li><li>在安卓5.0以前，主要使用虚拟机是Dalvik。使用dexopt优化生成文件为odex（无机器代码），主要组成有完整dex文件、odex文件头、依赖库列表、类索引信息等；</li><li>在art虚拟机模式下，<strong>oat文件</strong>直接包含了可在ART下运行的机器码，OAT中还有一份原始DEX的副本。</li><li>从8.0以后，Dex从Android 8.0后独立到<strong>vdex文件</strong>，dex2oat执行的转换会生成两个文件：classes.odex（实际上是oat文件）：包含本机代码的OAT和classes.vdex：包含原始DEX文件副本的VDEX文件。<br><img src="android_exec_files.png" alt="盗图：版权归LIEF项目拥有"> </li></ul><h2 id="2-安卓可执行文件"><a href="#2-安卓可执行文件" class="headerlink" title="2. 安卓可执行文件"></a>2. 安卓可执行文件</h2><ul><li><strong>OAT文件</strong>  <ul><li>OAT文件是一种Android私有ELF文件格式，是Android运行时ART的核心，不仅包含有从DEX文件翻译而来的本地机器指令，还包含有原来的DEX文件内容；</li><li>在 Android 8.0之后，dex2oat 生成的不再是单一个 OAT 文件，而是生成两个文件 classes.odex（实际是oat文件）跟 classes.vdex（dex 副本），odex + vdex = apk 的全部源码 （vdex 并不是独立于odex 的文件 odex + vdex 才代表一个apk );</li><li>Android &lt;=7可以从oat文件中提取dex，8.0以后只能从vdex中提取。  <br/><br/></li></ul></li><li><strong>ODEX文件</strong><ul><li>Android &lt;=4.4之前，使用dexopt优化DEX文件为odex，主要组成有完整dex文件、odex文件头、依赖库列表、类索引信息等；</li><li>在art模式下（5.0以后art为默认运行时环境），ODEX文件实质上是oat文件。<br><br/><br/></li></ul></li><li><strong>vdex文件</strong><ul><li>Android 8.0在odex的基础上又引入了vdex机制，目的是为了减少dex2oat中验证的时间；</li><li>verified dex，包含 raw dex +（quicken info)，文件头+打包的一些验证好的dex；</li><li>Dex从Android 8.0后独立到vdex文件，这个时候要逆向，一样可以从 vdex 中提取出 dex文件，再作逆向<br><br/><br/></li></ul></li><li><strong>cdex</strong><ul><li>cdex是Android 9推出的一种新型Dex文件，即Compact Dex（Cdex）。Cdex是一种ART内部文件格式，它压缩各种Dex数据结构（例如方法头）并对多索引文件中的常见数据blob（例如字符串）进行重复数据删除。来自输入应用程序的Dex文件的重复数据删除数据存储在Vdex容器的共享部分中。<br><br/><br/></li></ul></li><li><strong>Art</strong>   <ul><li>image文件，存储热点方法string，method，types等。</li></ul></li></ul><h2 id="3-安卓可执行文件的分析工具"><a href="#3-安卓可执行文件的分析工具" class="headerlink" title="3. 安卓可执行文件的分析工具"></a>3. 安卓可执行文件的分析工具</h2><h3 id="提取dex类"><a href="#提取dex类" class="headerlink" title="提取dex类"></a><strong>提取dex类</strong></h3><ul><li><a href="https://github.com/anestisb/vdexExtractor" target="_blank" rel="noopener">vdexExtractor &amp;&amp; compact_dex_converter_linux</a>（支持8.0、9.0的vdex提取）<ul><li>转化过程：<br><code>Vdex - &gt; dex (android 8)， vdex -&gt; cdex -&gt; dex (Android 9)</code></li><li>命令行：<br><code>Vdex-&gt;dex:  vdexExtractor -i /tmp/BasicDreams.vdex -o /tmp --deps -f   （9.0里会先转成cdex）</code><br><code>Cdex -&gt; dex:    compact_dex_converter_linux -w tmp ./wifi-service_classes.cdex  （注意：cdex转dex，后缀不会变，依然为dex）</code><br/><br/></li></ul></li><li><p>oatdump<br>（<em>安卓system/bin目录下自带，编译为共享文件，并且各个Android版本下的不通用，不便于做Android全系列的离线分析）<br>支持查看oat文件的类与方法，支持类名过滤，支持从oat中导出dex文件；其中，8.0和9.0指定oat或odex文件，但实际从vdex中提取dex，需将odex文件和vdex文件放在同一目录下</em>。  </p><ul><li>使用例子（dump services.odex中类名为PackageManagerService，方法为isPackageDeviceAdminOnAnyUse的相关信息）<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.oatdump --oat-file&#x3D;services.odex --class-filter&#x3D;PackageManagerService --method-filter&#x3D;isPackageDeviceAdminOnAnyUse</span><br></pre></td></tr></table></figure></li><li>也可以导出dex文件<br><code>Example: --export-dex-to=/data/local/tmp</code> <br/><br/></li></ul></li><li><p><a href="http://newandroidbook.com/tools/dextra.html" target="_blank" rel="noopener">dextra</a><br>支持从oat、odex、vdex中提取dex文件，支持查看dex、odex、oat、dex类、方法、字符串、符号等。安卓8.0、9.0的oat文件不支持查看，9.0的vdex不支持。</p></li></ul><ul><li><p><a href="https://github.com/JesusFreke/smali" target="_blank" rel="noopener">baksmali</a><br>主要用来反编译dex到jar，也可以从jar回编译到smali</p></li><li><p><a href="https://lief.quarkslab.com/doc/latest/Intro.html" target="_blank" rel="noopener">lief</a><br>用于解析和修改 ELF, PE 和MachO（mac平台上可执行文件）格式的跨平台库，支持Python调用，当然也支持dex、odex、oat、cdex的解析，不过当前不支持Android 9.0的可执行文件。</p></li></ul><h3 id="dex转jar"><a href="#dex转jar" class="headerlink" title="dex转jar"></a>dex转jar</h3><ul><li>dex2jar-2.0<br>d2j-dex2jar.bat wifi-service_classes.dex   （报版本错误时，将dex的版本改为0x36） </li></ul><h2 id="作者声明"><a href="#作者声明" class="headerlink" title="作者声明"></a><strong>作者声明</strong></h2><pre><code>本文版权归作者(rohex)所有，旨在技术交流使用。未经作者同意禁止转载，转载后需在文章页面明显位置给出原文连接，否则相关责任自行承担。</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Android </tag>
            
            <tag> OAT </tag>
            
            <tag> ODEX </tag>
            
            <tag> VDEX </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
